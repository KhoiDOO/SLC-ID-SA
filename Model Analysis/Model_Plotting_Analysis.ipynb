{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Plotting Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPydmh9qY4wTBQtstp+ZsEN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhoiDOO/Skin-Disease-Detection-and-Segmentation-HAM100000/blob/main/Model%20Analysis/Model_Plotting_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "vrfSjF597yib"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "def model_analyze(_model):\n",
        "    for x in range(len(_model.layers)):\n",
        "        print(f\"Layers {x}({x - len(_model.layers)}): {_model.layers[x].name}\")\n",
        "        \n",
        "def K_plot_model(_model, model_name):\n",
        "    plot_model(_model, \n",
        "               to_file=f\"{model_name}.png\", \n",
        "               show_shapes=True, \n",
        "               show_dtype=True,  \n",
        "               show_layer_names=True,\n",
        "               rankdir=\"LR\",\n",
        "               expand_nested=False,\n",
        "               dpi=10000,\n",
        "               show_layer_activations=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xception"
      ],
      "metadata": {
        "id": "kZd4wETb8Os-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xception = tf.keras.applications.Xception(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfEzv9Vt-Q3R",
        "outputId": "3f6aca3a-817f-4a72-bdc4-a1de6db9fb3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
            "91889664/91884032 [==============================] - 1s 0us/step\n",
            "91897856/91884032 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(xception, 'xception')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLE9WA1L-UKV",
        "outputId": "59b760d5-bf05-4498-d9d6-7f4abbf83a11"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.00564975 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG16"
      ],
      "metadata": {
        "id": "GPj4Q9j48P4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16 = tf.keras.applications.VGG16(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy4XEK0p_kfp",
        "outputId": "ef242e28-7bea-4bcb-89ba-bf6dbf5400eb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "553476096/553467096 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(VGG16, 'VGG16')"
      ],
      "metadata": {
        "id": "Ii1z1hGf_k9e"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG19"
      ],
      "metadata": {
        "id": "cRsLGrEq8P67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VGG19 = tf.keras.applications.VGG19(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJsO72Fy_om3",
        "outputId": "32064de5-085f-4dd6-de4a-40ed95b5e19f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 4s 0us/step\n",
            "574726144/574710816 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(VGG19, 'VGG19')"
      ],
      "metadata": {
        "id": "qVmXnVDd_rfi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet50"
      ],
      "metadata": {
        "id": "wt9uhYba8jJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50 = tf.keras.applications.ResNet50(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeFK46jf_x1M",
        "outputId": "a6cdc624-fd47-4451-ec86-f1bdb12bc16e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "102981632/102967424 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(ResNet50, 'ResNet50')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLM0SWAb_1K_",
        "outputId": "7dc07afc-36e0-4e3f-a979-dc37c83f55d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.288612 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet50V2"
      ],
      "metadata": {
        "id": "vkWbkeR18mo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50V2 = tf.keras.applications.ResNet50V2(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wwkHG8jAC2g",
        "outputId": "deb31f21-5f51-4c94-9d11-fb3e1ba73b93"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102875136/102869336 [==============================] - 1s 0us/step\n",
            "102883328/102869336 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(ResNet50V2, 'ResNet50V2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4q-M3V5AFJz",
        "outputId": "47397a4e-d870-4a30-b433-2d11333db79c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.258152 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet101"
      ],
      "metadata": {
        "id": "eAK42PmW8p4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet101 = tf.keras.applications.ResNet101(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro7Zw5WiALUm",
        "outputId": "40429278-ff41-4639-c210-1d63ed4f508d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels.h5\n",
            "179650560/179648224 [==============================] - 2s 0us/step\n",
            "179658752/179648224 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(ResNet101, 'ResNet101')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jz8mcKfAYO1",
        "outputId": "efbb21f3-ff69-4b8e-a1fa-f525b5349a04"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.141962 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet101V2"
      ],
      "metadata": {
        "id": "X6QGXUse8stW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet101V2 = tf.keras.applications.ResNet101V2(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJP4nqzYAbWn",
        "outputId": "3d28ca62-93ae-4a46-a07f-bf97f4594cd2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "179519488/179518384 [==============================] - 1s 0us/step\n",
            "179527680/179518384 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(ResNet101V2, 'ResNet101V2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58MMsyVcAdkk",
        "outputId": "fc4193f4-447d-4bc2-cc81-31275ab610b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.126425 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet152"
      ],
      "metadata": {
        "id": "GTui3Ay_8xCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet152 = tf.keras.applications.ResNet152(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWXGzD3xAh08",
        "outputId": "632d4e97-21d1-4ede-8f60-057b22d42863"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels.h5\n",
            "242900992/242900224 [==============================] - 3s 0us/step\n",
            "242909184/242900224 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(ResNet152, 'ResNet152')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXHHOTa-AkJ4",
        "outputId": "4d342a18-30ed-4894-ffb1-c186ad1035a3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.0942014 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet152V2"
      ],
      "metadata": {
        "id": "h8xRoSON8z0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet152V2 = tf.keras.applications.ResNet152V2(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMeJ-I6fAtnm",
        "outputId": "6b8d13f0-d317-4be8-8c5d-491b6eeb4d9b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "242753536/242745792 [==============================] - 1s 0us/step\n",
            "242761728/242745792 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(ResNet152V2, 'ResNet152V2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTGNGBTtA4fM",
        "outputId": "21fd45e1-51ef-4bcf-f7db-025c9fed3f28"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.0837677 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InceptionV3"
      ],
      "metadata": {
        "id": "4hzMq-gs82Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "InceptionV3 = tf.keras.applications.InceptionV3(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E7Q_ZyyA80F",
        "outputId": "f8ac3518-ec30-4c1b-e6fd-f99f52e0281f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "96124928/96112376 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(InceptionV3, 'InceptionV3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8XdHpXKA_FO",
        "outputId": "574883a2-3310-42f4-d3c1-d782592de712"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.295172 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InceptionResnetV2"
      ],
      "metadata": {
        "id": "zVoupdxe849e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "InceptionResNetV2 = tf.keras.applications.InceptionResNetV2(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsR2-YRkBT8w",
        "outputId": "00b6d787-f1a0-4830-a80b-79ca0020ea22"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "225214464/225209952 [==============================] - 2s 0us/step\n",
            "225222656/225209952 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(InceptionResNetV2, 'InceptionResNetV2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta7mc53MBW08",
        "outputId": "58849c3a-2437-411f-f5a0-31de5298fa4f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.0873796 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNet"
      ],
      "metadata": {
        "id": "mvgQWe-v89uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNet = tf.keras.applications.MobileNet(\n",
        "    input_shape=None,\n",
        "    alpha=1.0,\n",
        "    depth_multiplier=1,\n",
        "    dropout=0.001,\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9outxEw4BZAG",
        "outputId": "f97c9e39-2e91-4565-e7a0-5131169f883f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "17235968/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(MobileNet, 'MobileNet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd8v-sZCBjxj",
        "outputId": "4b46e7b2-aab3-4d01-fafe-73fca98c7bec"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.599009 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNetV2"
      ],
      "metadata": {
        "id": "AxJ0k-mX9QT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetV2 = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=None,\n",
        "    alpha=1.0,\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2knXbSuGBncy",
        "outputId": "0bf5a3c9-8612-40b4-afca-01036023c1b0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14540800/14536120 [==============================] - 0s 0us/step\n",
            "14548992/14536120 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(MobileNetV2, 'MobileNetV2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo1janiPBryS",
        "outputId": "4f6481ad-e955-498d-8081-c36cb5b55655"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.31341 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DenseNet121"
      ],
      "metadata": {
        "id": "jU9RD5A89Ukk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DenseNet121 = tf.keras.applications.DenseNet121(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-qlzG-hByuz",
        "outputId": "f8247481-d64d-4ea8-871d-73612217feda"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n",
            "33193984/33188688 [==============================] - 0s 0us/step\n",
            "33202176/33188688 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(DenseNet121, 'DenseNet121')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzuqa9MvB0nj",
        "outputId": "de4c352a-b8ae-4e97-b224-1129e03aca46"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.111815 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DenseNet169"
      ],
      "metadata": {
        "id": "kbacbu1D9d5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DenseNet169 = tf.keras.applications.DenseNet169(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgyy3xH5B5-H",
        "outputId": "fef6098e-187e-4a83-8018-f76cc71f2b62"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels.h5\n",
            "58548224/58541896 [==============================] - 1s 0us/step\n",
            "58556416/58541896 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(DenseNet169, 'DenseNet169')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz9MMYtVB7-l",
        "outputId": "f360ebae-1e63-49e5-b98a-ec87396b1a2b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.0798169 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DenseNet201"
      ],
      "metadata": {
        "id": "pXhPvS_H9gq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DenseNet201 = tf.keras.applications.DenseNet201(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QXfGlGGB-Vw",
        "outputId": "0d03ab49-0209-4a78-bb03-18f2998440d1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels.h5\n",
            "82526208/82524592 [==============================] - 3s 0us/step\n",
            "82534400/82524592 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(DenseNet201, 'DenseNet201')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma9Hj9dYCAjb",
        "outputId": "bcfd2eeb-0657-453e-ca7c-445804f9320e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.0670319 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NASNetMobile"
      ],
      "metadata": {
        "id": "aZvYDxSu9lWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NASNetMobile = tf.keras.applications.NASNetMobile(\n",
        "    input_shape=None,\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ_QwZ1NCEWL",
        "outputId": "ca287f87-f9b2-4347-bd5c-4d02072198e5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile.h5\n",
            "24231936/24227760 [==============================] - 0s 0us/step\n",
            "24240128/24227760 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(NASNetMobile, 'NASNetMobile')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agvZ9soDCGjq",
        "outputId": "3c340c42-438c-4f84-f606-350487c00c9f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.179028 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NASNetLarge "
      ],
      "metadata": {
        "id": "fePRd5Ay9o5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NASNetLarge = tf.keras.applications.NASNetLarge(\n",
        "    input_shape=None,\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yklzn5JzCLwE",
        "outputId": "2a7f65b5-0852-4d5d-e8ee-1f80cff3faec"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large.h5\n",
            "359751680/359748576 [==============================] - 3s 0us/step\n",
            "359759872/359748576 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(NASNetLarge, 'NASNetLarge')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QihOq_y9CNUT",
        "outputId": "21a146a9-b9eb-49ed-c72e-edfc4f93c58a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.136022 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB0"
      ],
      "metadata": {
        "id": "KsH0Mmcr97aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB0 = tf.keras.applications.EfficientNetB0(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kO7IKfqCTK0",
        "outputId": "0f7a5ba6-9b38-46a8-e57b-d8a0e03cfb45"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0.h5\n",
            "21839872/21834768 [==============================] - 0s 0us/step\n",
            "21848064/21834768 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(EfficientNetB0, 'EfficientNetB0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylVrrs49CXzl",
        "outputId": "b13c985f-4296-479a-aaec-7f2d5749ec5c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.208976 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB1"
      ],
      "metadata": {
        "id": "ghS1E_J7-CyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB1 = tf.keras.applications.EfficientNetB1(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9XemBm2CaZ9",
        "outputId": "cdf64dc6-4c7d-4bdf-a993-dfc029aed5a1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1.h5\n",
            "32153600/32148312 [==============================] - 0s 0us/step\n",
            "32161792/32148312 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(EfficientNetB1, 'EfficientNetB1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpNWPIo8CcjK",
        "outputId": "e0076b69-b8a8-450a-a892-4cc645820c1a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.146663 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB2"
      ],
      "metadata": {
        "id": "DxVe64F1-EZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB2 = tf.keras.applications.EfficientNetB2(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW5sj5uVCfRG",
        "outputId": "d49b6e23-f5ed-4cc7-fb49-6e99294df770"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2.h5\n",
            "37437440/37432240 [==============================] - 0s 0us/step\n",
            "37445632/37432240 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(EfficientNetB2, 'EfficientNetB2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYPua725Chod",
        "outputId": "857c7d57-af77-4e88-f2c5-c60cdaee1e2b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.146654 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB3"
      ],
      "metadata": {
        "id": "p1uv1FLx-FfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB3 = tf.keras.applications.EfficientNetB3(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1zCMloJCkSZ",
        "outputId": "f46b1b7d-0c66-4a86-9263-d4b97dbb4e6d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3.h5\n",
            "50102272/50095040 [==============================] - 0s 0us/step\n",
            "50110464/50095040 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(EfficientNetB3, 'EfficientNetB3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBSVU25xCmkt",
        "outputId": "143e1e45-eb0c-4e20-b715-50193cbe7c42"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.129336 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB4"
      ],
      "metadata": {
        "id": "zOY-BHQz-Hy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB4 = tf.keras.applications.EfficientNetB4(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcroVjJ9CqG5",
        "outputId": "e873a462-86eb-4f83-8d10-d713dcdc9d8a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4.h5\n",
            "78872576/78864416 [==============================] - 1s 0us/step\n",
            "78880768/78864416 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(EfficientNetB4, 'EfficientNetB4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyI2-CSpCss7",
        "outputId": "adc4ddf6-ec27-442a-bbfa-b96b074443a4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.10488 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB5"
      ],
      "metadata": {
        "id": "hPAKsdMY-JHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB5 = tf.keras.applications.EfficientNetB5(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMjVRPRvC21t",
        "outputId": "3c6bd265-54a0-40b6-ed63-34e4de5c72c6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5.h5\n",
            "123469824/123465288 [==============================] - 1s 0us/step\n",
            "123478016/123465288 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(EfficientNetB5, 'EfficientNetB5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzMWZr_UC5PU",
        "outputId": "9382ff99-0451-4807-959d-a43731b5e479"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.0863028 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB6"
      ],
      "metadata": {
        "id": "C3iKh99N-KtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB6 = tf.keras.applications.EfficientNetB6(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tlfy4hnC70i",
        "outputId": "f98b2771-a538-41d0-9182-527f756f1e8d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6.h5\n",
            "174465024/174460376 [==============================] - 2s 0us/step\n",
            "174473216/174460376 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(EfficientNetB6, 'EfficientNetB6')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTkxH-glC-ZQ",
        "outputId": "9636c826-19d3-4aea-965f-87e28b6e1372"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.0746908 to fit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB7"
      ],
      "metadata": {
        "id": "dwquBDAu-MQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB7 = tf.keras.applications.EfficientNetB7(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUcWd_xEDARr",
        "outputId": "8b5f9c23-cf86-479c-8463-438cfe8ee199"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7.h5\n",
            "268328960/268326632 [==============================] - 2s 0us/step\n",
            "268337152/268326632 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_plot_model(EfficientNetB7, 'EfficientNetB7')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTA6_-dcDCWh",
        "outputId": "5b97b104-28a9-487a-c818-1b5901c7aedd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.0612496 to fit\n",
            "\n"
          ]
        }
      ]
    }
  ]
}