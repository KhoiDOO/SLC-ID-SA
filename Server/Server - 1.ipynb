{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "776a64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "from keras import layers\n",
    "import keras.layers as kl\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import callbacks \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from  matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import concatenate, Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, AveragePooling2D, BatchNormalization, Dropout\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "#Server Deployment\n",
    "from flask import Flask, send_file, request, jsonify, make_response, current_app\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask_cors import CORS\n",
    "from functools import update_wrapper, wraps\n",
    "from pyngrok import ngrok\n",
    "import requests\n",
    "\n",
    "#Diagnosis\n",
    "from ipywidgets import Button\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import clear_output, display\n",
    "from beautifultable import BeautifulTable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e341906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76b19c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variable\n",
    "main_dir = 'D:/Data/HAM100000 - Harvard Dataset'\n",
    "main_img_dir = main_dir + '/img_data'\n",
    "preprocessed_data_dir = main_dir + '/preprocessed_data'\n",
    "train_dir = preprocessed_data_dir + '/train'\n",
    "test_dir = preprocessed_data_dir + '/val'\n",
    "train_label = preprocessed_data_dir + '/train_label.csv'\n",
    "val_label = preprocessed_data_dir + '/val_label.csv'\n",
    "\n",
    "aug_label = preprocessed_data_dir + '/aug_label.csv'\n",
    "aug_img_data_dir = main_dir + '/augmented_data'\n",
    "\n",
    "# ModelPath\n",
    "main_git_dir = 'D:/GithubCloneRepo/Skin-Disease-Detection-and-Segmentation-HAM100000'\n",
    "experiment_dir = main_git_dir + '/Experiment'\n",
    "\n",
    "dense_net_dir = experiment_dir + '/DenseNet201 - SoftAtt'\n",
    "mobilenetV3_dir = experiment_dir + '/MobileNetV3'\n",
    "model_densenet_path = dense_net_dir + '/densenetSoftAtt_10split_LRStr.hdf5'\n",
    "model_mobilev3_path = mobilenetV3_dir + '/mobilenetv3LargeSoftAtt_10split_LRStr.hdf5'\n",
    "\n",
    "full_model_path = 'D:/GitCloneProject/Skin-Disease-Detection-and-Segmentation-HAM100000/Experiment/DenseNet201 - SoftAtt' + '/densenetSoftAtt_10split_LRStr.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bf7c14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      image_id   dx   age   sex localization\n",
       "0           0  ISIC_0027419  bkl  80.0  male        scalp\n",
       "1           1  ISIC_0025030  bkl  80.0  male        scalp\n",
       "2           2  ISIC_0026769  bkl  80.0  male        scalp\n",
       "3           3  ISIC_0025661  bkl  80.0  male        scalp\n",
       "4           4  ISIC_0031633  bkl  75.0  male          ear"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_label)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2923d560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9382</td>\n",
       "      <td>ISIC_0025101</td>\n",
       "      <td>nv</td>\n",
       "      <td>5.0</td>\n",
       "      <td>female</td>\n",
       "      <td>foot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1741</td>\n",
       "      <td>ISIC_0033444</td>\n",
       "      <td>mel</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9974</td>\n",
       "      <td>ISIC_0024654</td>\n",
       "      <td>akiec</td>\n",
       "      <td>75.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4429</td>\n",
       "      <td>ISIC_0026747</td>\n",
       "      <td>nv</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>445</td>\n",
       "      <td>ISIC_0025928</td>\n",
       "      <td>bkl</td>\n",
       "      <td>85.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      image_id     dx   age     sex     localization\n",
       "0        9382  ISIC_0025101     nv   5.0  female             foot\n",
       "1        1741  ISIC_0033444    mel  50.0    male          abdomen\n",
       "2        9974  ISIC_0024654  akiec  75.0  female  lower extremity\n",
       "3        4429  ISIC_0026747     nv  40.0    male  lower extremity\n",
       "4         445  ISIC_0025928    bkl  85.0  female             back"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv(val_label)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0b0fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_input = tf.keras.Input(shape=(1,), name='age', dtype=tf.float32)\n",
    "sex_input = tf.keras.Input(shape=(1,), name='sex', dtype=tf.string)\n",
    "localizations_input = tf.keras.Input(shape=(1,), name='localization', dtype=tf.string)\n",
    "\n",
    "inputs = {'age' : age_input,\n",
    "         'sex' : sex_input,\n",
    "         'local' : localizations_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09706677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'normalization_1')>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(train_df[['age']]))\n",
    "age_norm_input = norm(age_input)\n",
    "age_norm_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e9d722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'category_encoding_2')>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sex input\n",
    "sex_lookup = layers.StringLookup(vocabulary=np.unique(train_df['sex']))\n",
    "sex_one_hot = layers.CategoryEncoding(num_tokens=sex_lookup.vocabulary_size())\n",
    "\n",
    "preprocessed_sex_input = sex_lookup(sex_input)\n",
    "preprocessed_sex_input = sex_one_hot(preprocessed_sex_input)\n",
    "preprocessed_sex_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2296826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 16) dtype=float32 (created by layer 'category_encoding_3')>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Localization input\n",
    "local_lookup = layers.StringLookup(vocabulary=np.unique(train_df['localization']))\n",
    "local_one_hot = layers.CategoryEncoding(num_tokens=local_lookup.vocabulary_size())\n",
    "\n",
    "preprocess_local_input = local_lookup(localizations_input)\n",
    "preprocess_local_input = local_one_hot(preprocess_local_input)\n",
    "preprocess_local_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7eba2c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 21) dtype=float32 (created by layer 'concatenate_3')>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_inputs = [age_norm_input, preprocessed_sex_input, preprocess_local_input]\n",
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "# preprocessed_Model = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "# tf.keras.utils.plot_model(model = preprocessed_Model , rankdir=\"LR\", dpi=72, show_shapes=True)\n",
    "\n",
    "preprocessed_inputs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61558b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "178aed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftAttention(Layer):\n",
    "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
    "        self.channels=int(ch)\n",
    "        self.multiheads = m\n",
    "        self.aggregate_channels = aggregate\n",
    "        self.concat_input_with_scaled = concat_with_x\n",
    "\n",
    "        \n",
    "        super(SoftAttention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.i_shape = input_shape\n",
    "\n",
    "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
    "    \n",
    "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "\n",
    "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
    "        else:\n",
    "            if self.concat_input_with_scaled:\n",
    "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
    "            else:\n",
    "                self.out_features_shape = input_shape\n",
    "        \n",
    "\n",
    "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
    "                                        initializer='he_uniform',\n",
    "                                        name='kernel_conv3d')\n",
    "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_conv3d')\n",
    "\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        exp_x = K.expand_dims(x,axis=-1)\n",
    "\n",
    "        c3d = K.conv3d(exp_x,\n",
    "                     kernel=self.kernel_conv3d,\n",
    "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
    "        conv3d = K.bias_add(c3d,\n",
    "                        self.bias_conv3d)\n",
    "        conv3d = kl.Activation('relu')(conv3d)\n",
    "\n",
    "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
    "\n",
    "        \n",
    "        conv3d = K.squeeze(conv3d, axis=-1)\n",
    "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
    "\n",
    "        softmax_alpha = K.softmax(conv3d, axis=-1) \n",
    "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
    "\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)       \n",
    "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
    "   \n",
    "            x_exp = K.expand_dims(x,axis=-2)\n",
    "   \n",
    "            u = kl.Multiply()([exp_softmax_alpha, x_exp])   \n",
    "  \n",
    "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
    "\n",
    "        else:\n",
    "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
    "\n",
    "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
    "\n",
    "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
    "\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x])   \n",
    "\n",
    "        if self.concat_input_with_scaled:\n",
    "            o = kl.Concatenate(axis=-1)([u,x])\n",
    "        else:\n",
    "            o = u\n",
    "        \n",
    "        return [o, softmax_alpha]\n",
    "\n",
    "    def compute_output_shape(self, input_shape): \n",
    "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
    "\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(SoftAttention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "497c1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = tf.keras.applications.DenseNet201(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "\n",
    ")\n",
    "\n",
    "inputs['image'] = densenet.input\n",
    "\n",
    "# Exclude the last 28 layers of the model.\n",
    "densenet_output = densenet.layers[-28].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efd0f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(densenet_output.shape[-1]),name='soft_attention')(densenet_output)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "densenet_output=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(densenet_output))\n",
    "\n",
    "densenet_output = layers.Concatenate()([densenet_output, attention_layer])\n",
    "densenet_output = Activation('relu')(densenet_output)\n",
    "densenet_output = Dropout(0.5)(densenet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50a07d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Flatten()(densenet_output)\n",
    "preprocessed_inputs_cat = (layers.Dense(4096, activation = 'relu')(preprocessed_inputs_cat))\n",
    "output = layers.Concatenate()([output, preprocessed_inputs_cat])\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57a6c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "with tf.device('/GPU:0'):\n",
    "    model.load_weights(full_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51672a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 31.125 batches). You may need to use the repeat() function when building your dataset.\n",
      "[9.2421025e-01 1.9629026e-05 2.7033087e-05 3.6897184e-06 1.1086434e-05\n",
      " 7.5725958e-02 2.3348568e-06]\n",
      "<class 'numpy.ndarray'>\n",
      "[2 5 0]\n",
      "Ung thư tế bào vảy khu trú\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "img_path_test = train_dir + '/akiec/ISIC_0024329.jpg'\n",
    "_img = cv2.imread(img_path_test)\n",
    "sex_lst = ['male', 'female']\n",
    "local_lst = ['back','lower extremity', 'trunk','upper extremity', 'abdomen','face','chest','foot','unknown','neck','scalp',                    \n",
    "'hand', 'ear', 'genital', 'acral']  \n",
    "\n",
    "_img = tf.keras.preprocessing.image.smart_resize(_img, (224,224))\n",
    "_img = tf.keras.applications.mobilenet.preprocess_input(_img)\n",
    "\n",
    "val_dict = {'age' : np.array([15]),\n",
    "                'sex' : np.array([sex_lst[0]]),\n",
    "                'local' : np.array([local_lst[0]]),\n",
    "                'image' : np.array([_img])}\n",
    "\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "targetnames_vn = ['Ung thư tế bào vảy khu trú', 'Ung thư biểu mô tế bào đấy', 'Dày sừng tiết bã', 'U sợi bì', 'Ung thư hắc tố da', 'Nốt ruồi', 'U mạch anh đào']\n",
    "\n",
    "batch_size = 32 \n",
    "with tf.device('/CPU:0'):\n",
    "    predictions = model.predict(val_dict, steps=len(val_df)/batch_size, verbose=0)[0]\n",
    "    print(predictions)\n",
    "    print(type(predictions))\n",
    "    \n",
    "    ind = np.argpartition(predictions, 3)[-3:]\n",
    "    print(ind)\n",
    "    \n",
    "    print(targetnames_vn[ind[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb3b3363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ung thư tế bào vảy khu trú (akiec)': 92.42, 'Nốt ruồi (nv)': 7.57, 'Dày sừng tiết bã (bkl)': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# utils\n",
    "def make_predict(_img_path, _sex, _age, _local):\n",
    "    with tf.device('/CPU:0'):\n",
    "        _img = cv2.imread(_img_path)\n",
    "        _img = tf.keras.preprocessing.image.smart_resize(_img, (224,224))\n",
    "        _img = tf.keras.applications.mobilenet.preprocess_input(_img)\n",
    "        val_dict = {'age' : np.array([_age]),\n",
    "                    'sex' : np.array([_sex]),\n",
    "                    'local' : np.array([_local]),\n",
    "                    'image' : np.array([_img])}\n",
    "        predictions = model.predict(val_dict, verbose=0)[0]\n",
    "        ind = np.argpartition(predictions, 3)[-3:]\n",
    "        return {targetnames_vn[ind[2]] + \" ({})\".format(targetnames[ind[2]]) : round(predictions[ind[2]]*100, 2),\n",
    "               targetnames_vn[ind[1]] + \" ({})\".format(targetnames[ind[1]]) : round(predictions[ind[1]]*100, 2),\n",
    "               targetnames_vn[ind[0]] + \" ({})\".format(targetnames[ind[0]]) : round(predictions[ind[0]]*100, 2)}\n",
    "\n",
    "def test(_img_path, _sex, _age, _local):\n",
    "    test_dict = make_predict(_img_path, _sex, _age, _local)\n",
    "    print(test_dict)\n",
    "    \n",
    "test(img_path_test, 'male', 15, 'back')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3865bc5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ung thư biểu mô tế bào đấy (bcc)': 98.68, 'Nốt ruồi (nv)': 1.32, 'U mạch anh đào (vasc)': 0.0}\n"
     ]
    }
   ],
   "source": [
    "main_filename = 'D:/GitCloneProject/Skin-Disease-Detection-and-Segmentation-HAM100000/Server/IMG_Storage_File/{}.jpg'\n",
    "test(main_filename.format('ISIC_0024431'), 'male', 15, 'back')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b7a0bbe",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a513a876f694e1ebb3c713342276641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='File select', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = BeautifulTable()\n",
    "\n",
    "def select_files(b):\n",
    "    clear_output()\n",
    "    root = Tk()\n",
    "    root.withdraw() # Hide the main window.\n",
    "    root.call('wm', 'attributes', '.', '-topmost', True) # Raise the root to the top of all windows.\n",
    "    b.files = filedialog.askopenfilename(multiple=True) # List of selected files will be set button's file attribute.\n",
    "#     print(b.files[0]) # Print the list of files selected.\n",
    "    test_dict = make_predict(b.files[0], 'male', 15, 'back')\n",
    "    print(\"Diagnosis Result\")\n",
    "    img = mpimg.imread(b.files[0])\n",
    "    imgplot = plt.imshow(img)\n",
    "    table.rows.append(test_dict.keys())\n",
    "    table.rows.append(list(test_dict.values()))\n",
    "    print(table)\n",
    "    \n",
    "fileselect = Button(description=\"File select\")\n",
    "fileselect.on_click(select_files)\n",
    "\n",
    "display(fileselect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57cb647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To access the Global link please click http://8318-2001-ee0-4001-b87f-901b-291d-cd8b-9cd7.ngrok.io\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Jun/2022 18:30:48] \"POST /upload/test1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:31:05] \"POST /upload/test1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:31:12] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:33:25] \"POST /upload/img_1655638396356 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:33:26] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:33:27] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:36:27] \"POST /upload/img_1655638569004 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:36:37] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:36:39] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:36:40] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:41:20] \"POST /upload/img_1655638872613 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:41:22] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 18:41:23] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:43:23] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "[2022-06-19 20:43:25,352] ERROR in app: Exception on /diagnosis [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 2073, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 1518, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask_cors\\extension.py\", line 165, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 1516, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 1502, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20144\\2379402294.py\", line 35, in diagnosis\n",
      "    return jsonify(make_predict(filepath, json_data['sex'], json_data['age'], json_data['local']))\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20144\\2831936182.py\", line 5, in make_predict\n",
      "    _img = tf.keras.preprocessing.image.smart_resize(_img, (224,224))\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 108, in smart_resize\n",
      "    img = tf.convert_to_tensor(x)\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.\n",
      "127.0.0.1 - - [19/Jun/2022 20:43:25] \"POST /diagnosis HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:43:30] \"POST /upload/img_1655646187391 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:44:27] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "[2022-06-19 20:44:28,298] ERROR in app: Exception on /diagnosis [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 2073, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 1518, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask_cors\\extension.py\", line 165, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 1516, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 1502, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20144\\2379402294.py\", line 35, in diagnosis\n",
      "    return jsonify(make_predict(filepath, json_data['sex'], json_data['age'], json_data['local']))\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20144\\2831936182.py\", line 5, in make_predict\n",
      "    _img = tf.keras.preprocessing.image.smart_resize(_img, (224,224))\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 108, in smart_resize\n",
      "    img = tf.convert_to_tensor(x)\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.\n",
      "127.0.0.1 - - [19/Jun/2022 20:44:28] \"POST /diagnosis HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:44:28] \"POST /upload/img_1655646255397 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:45:54] \"POST /upload/img_1655646346248 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:45:54] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:45:56] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:46:08] \"POST /upload/img_1655646333373 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:46:09] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 20:46:10] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 21:50:18] \"POST /upload/img_1655650185324 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 21:50:29] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 21:50:31] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:18:55] \"POST /upload/img_1655655469096 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:19:07] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:19:08] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:19:08] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:31:27] \"POST /upload/img_1655656280159 HTTP/1.1\" 400 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:31:41] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "[2022-06-19 23:31:42,446] ERROR in app: Exception on /diagnosis [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 2073, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 1518, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask_cors\\extension.py\", line 165, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 1516, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\flask\\app.py\", line 1502, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20144\\2379402294.py\", line 35, in diagnosis\n",
      "    return jsonify(make_predict(filepath, json_data['sex'], json_data['age'], json_data['local']))\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20144\\2831936182.py\", line 5, in make_predict\n",
      "    _img = tf.keras.preprocessing.image.smart_resize(_img, (224,224))\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 108, in smart_resize\n",
      "    img = tf.convert_to_tensor(x)\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"d:\\env\\tf270\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.\n",
      "127.0.0.1 - - [19/Jun/2022 23:31:42] \"POST /diagnosis HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:43:05] \"POST /upload/img_1655656903362 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:43:18] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:43:19] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:44:17] \"POST /upload/img_1655657034408 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Jun/2022 23:44:19] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:44:20] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:44:21] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:46:16] \"POST /upload/img_1655657161966 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:46:23] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:46:24] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:48:25] \"POST /upload/img_1655657291774 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:48:29] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:48:30] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2022 23:48:31] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 00:28:56] \"POST /upload/img_1655659726273 HTTP/1.1\" 400 -\n",
      "127.0.0.1 - - [20/Jun/2022 00:30:07] \"POST /upload/img_1655659796755 HTTP/1.1\" 400 -\n",
      "127.0.0.1 - - [20/Jun/2022 00:49:30] \"POST /upload/img_1655660958197 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 00:49:32] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 00:49:33] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 00:49:37] \"GET /download/img_1655660958197 HTTP/1.1\" 200 -\n",
      "t=2022-06-20T10:06:44+0700 lvl=eror msg=\"heartbeat timeout, terminating session\" obj=csess id=90bf90e242bb clientid=287d8db22b103dda318b58914aff1a44\n",
      "t=2022-06-20T10:06:44+0700 lvl=eror msg=\"session closed, starting reconnect loop\" obj=csess id=5ebf763834e6 err=\"session closed\"\n",
      "t=2022-06-20T10:06:54+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"dial tcp 192.168.111.1:443: i/o timeout\"\n",
      "t=2022-06-20T10:07:05+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"dial tcp 192.168.111.1:443: i/o timeout\"\n",
      "t=2022-06-20T10:07:15+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"Get \\\"https://dns.google.com/resolve?cd=true&name=tunnel.us.ngrok.com&type=A\\\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\"\n",
      "t=2022-06-20T10:07:26+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"Get \\\"https://s3.amazonaws.com/dns.ngrok.com/tunnel.json\\\": context deadline exceeded\"\n",
      "t=2022-06-20T10:07:27+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"resolved tunnel.us.ngrok.com has no records\"\n",
      "t=2022-06-20T10:07:39+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"dial tcp 192.168.111.1:443: i/o timeout\"\n",
      "t=2022-06-20T10:07:51+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"Get \\\"https://dns.google.com/resolve?cd=true&name=tunnel.us.ngrok.com&type=A\\\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\"\n",
      "t=2022-06-20T10:08:05+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"Get \\\"https://s3.amazonaws.com/dns.ngrok.com/tunnel.json\\\": context deadline exceeded\"\n",
      "t=2022-06-20T10:08:10+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"resolved tunnel.us.ngrok.com has no records\"\n",
      "t=2022-06-20T10:08:27+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"dial tcp 192.168.111.1:443: i/o timeout\"\n",
      "t=2022-06-20T10:08:48+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"dial tcp 192.168.111.1:443: i/o timeout\"\n",
      "t=2022-06-20T10:09:12+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"dial tcp 192.168.111.1:443: i/o timeout\"\n",
      "t=2022-06-20T10:09:44+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"Get \\\"https://dns.google.com/resolve?cd=true&name=tunnel.us.ngrok.com&type=AAAA\\\": context deadline exceeded\"\n",
      "t=2022-06-20T10:10:24+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"Get \\\"https://s3.amazonaws.com/dns.ngrok.com/tunnel.json\\\": context deadline exceeded\"\n",
      "t=2022-06-20T10:10:54+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"resolved tunnel.us.ngrok.com has no records\"\n",
      "t=2022-06-20T10:11:25+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"x509: certificate is valid for tunnel.us.ngrok.com, not korgn.su.lennut.com\"\n",
      "t=2022-06-20T10:11:55+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"x509: certificate is valid for tunnel.us.ngrok.com, not korgn.su.lennut.com\"\n",
      "t=2022-06-20T10:12:36+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"Get \\\"https://s3.amazonaws.com/dns.ngrok.com/tunnel.json\\\": context deadline exceeded\"\n",
      "t=2022-06-20T10:13:06+0700 lvl=eror msg=\"failed to reconnect session\" obj=csess id=5ebf763834e6 err=\"resolved tunnel.us.ngrok.com has no records\"\n",
      "127.0.0.1 - - [20/Jun/2022 10:32:03] \"POST /upload/img_1655695912595 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:32:04] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:32:06] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:32:10] \"GET /download/img_1655695912595 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:34:29] \"POST /upload/img_1655696056197 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:34:30] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:34:31] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:34:37] \"GET /download/img_1655696056197 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:35:45] \"POST /upload/img_1655696127118 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:35:48] \"OPTIONS /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:35:49] \"POST /diagnosis HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 10:35:53] \"GET /download/img_1655696127118 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Home page of server\n",
    "# !ngrok config add-authtoken 2AnC9szbri9GPw0kmnmKWKs5II4_6Jt8tgMqEZ7tPHbeCGVKq\n",
    "app = Flask(__name__)\n",
    "port_no = 5000\n",
    "ngrok.set_auth_token(\"2AnC9szbri9GPw0kmnmKWKs5II4_6Jt8tgMqEZ7tPHbeCGVKq\")\n",
    "public_url = ngrok.connect(port_no).public_url\n",
    "CORS(app)\n",
    "# run_with_ngrok(app)\n",
    "print(f\"To access the Global link please click {public_url}\")\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return \"<h1>SkinUNI Server</h1>\"\n",
    "\n",
    "@app.route('/download/<path:filename>')\n",
    "def get_file(filename):\n",
    "    trans_filepath = main_filename.format(filename)\n",
    "    return send_file(trans_filepath)\n",
    "\n",
    "@app.route('/upload/<path:filename>', methods= ['GET', 'POST'])\n",
    "def upload_file(filename):\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['files']\n",
    "        filepath = main_filename.format(filename)\n",
    "        f.save(filepath)\n",
    "        return '200'\n",
    "    else:\n",
    "        return 'Upload ONLY'\n",
    "\n",
    "@app.route('/diagnosis', methods= ['GET', 'POST'])\n",
    "def diagnosis():\n",
    "    if request.method == 'POST':\n",
    "        json_data = request.json\n",
    "        filepath = main_filename.format(json_data['path'])\n",
    "        return jsonify(make_predict(filepath, json_data['sex'], json_data['age'], json_data['local']))\n",
    "        \n",
    "app.run(port=port_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e4ec23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
