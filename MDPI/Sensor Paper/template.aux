\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{Definitions/mdpi}
\citation{03358}
\citation{03358}
\citation{11872}
\citation{11872}
\citation{11872}
\citation{11872}
\newmarginnote{note.1.1}{{1}{10945661sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Problem Statement}{1}{subsection.1.1}\protected@file@percent }
\citation{06993}
\citation{04861}
\citation{00567}
\citation{04861}
\citation{04381}
\citation{02244}
\citation{03385}
\citation{05027}
\citation{07012}
\citation{03358}
\citation{06993}
\citation{00567}
\citation{03385}
\citation{05027}
\citation{1556}
\citation{03798}
\citation{10348}
\citation{00567}
\citation{09418}
\citation{11946}
\citation{01507}
\citation{04552v2}
\citation{01284}
\citation{06612}
\citation{03225}
\citation{12602}
\citation{03426}
\citation{03910}
\citation{03798}
\citation{10348}
\citation{05045}
\citation{03358}
\citation{03798}
\citation{10348}
\citation{09418}
\citation{01284}
\citation{06612}
\citation{03225}
\citation{12602}
\citation{03426}
\citation{03910}
\citation{03798}
\citation{10348}
\citation{05045}
\citation{10348}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Related Works}{2}{subsection.1.2}\protected@file@percent }
\citation{10417}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Related Works Summary. This table is a summary of the approach to skin lesion classification and segmentation. The first column illustrate the cite to the paper research. Column 2 shows a brief summary of the method that is stated in the associated paper.\relax }}{3}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table:related-work-summary}{{1}{3}{Related Works Summary. This table is a summary of the approach to skin lesion classification and segmentation. The first column illustrate the cite to the paper research. Column 2 shows a brief summary of the method that is stated in the associated paper.\relax }{table.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Objectives}{3}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Materials and Methods}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Image Data}{3}{subsubsection.2.1.1}\protected@file@percent }
\citation{03358}
\citation{06993}
\citation{03385}
\citation{05027}
\citation{11946}
\citation{04861}
\citation{04381}
\citation{02244}
\citation{07012}
\citation{10417}
\citation{03910}
\citation{08375}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Data Distribution in HAM10000. This table illustrate the distribution of all class in the data set. The detail name of the skin disease in the data set can be found at the Abbreviations\relax }}{4}{table.caption.2}\protected@file@percent }
\newlabel{table:data-distribution}{{2}{4}{Data Distribution in HAM10000. This table illustrate the distribution of all class in the data set. The detail name of the skin disease in the data set can be found at the Abbreviations\relax }{table.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example image of each class\relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:data-sample}{{1}{4}{Example image of each class\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Metadata}{4}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Model Schema}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Input Schema}{4}{subsubsection.2.2.1}\protected@file@percent }
\citation{03044}
\citation{202017}
\citation{03358}
\citation{08513}
\citation{03358}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Input Schema\relax }}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:input-schema}{{2}{5}{Input Schema\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Soft-Attention}{5}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Soft-Attention Module\relax }}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:soft-attention}{{3}{5}{Soft-Attention Module\relax }{figure.caption.5}{}}
\citation{06993}
\citation{00567}
\citation{04861}
\citation{04381}
\citation{02244}
\citation{03385}
\citation{05027}
\citation{07012}
\citation{03358}
\citation{07261}
\citation{03358}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Soft-Attention Module\relax }}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:soft-attention-block}{{4}{6}{Soft-Attention Module\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Backbone Model Architecture}{6}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Size and Parameters and Depth of backbone model used in this paper. This table summarizes the properties of the backbone models. The size column illustrates how many space need to store the model in megabyte. The parameters column demonstrate the number of parameters in the associated model. The last column, depth show the number of hidden layers in that model. Parameters and Depth are two crucial element to evaluate the optimized model stated in the Objective section.\relax }}{6}{table.caption.7}\protected@file@percent }
\newlabel{table:model-summary}{{3}{6}{Size and Parameters and Depth of backbone model used in this paper. This table summarizes the properties of the backbone models. The size column illustrates how many space need to store the model in megabyte. The parameters column demonstrate the number of parameters in the associated model. The last column, depth show the number of hidden layers in that model. Parameters and Depth are two crucial element to evaluate the optimized model stated in the Objective section.\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Model}{6}{subsubsection.2.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Overall Mobile-based Model Architecture\relax }}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:main-model}{{5}{7}{Overall Mobile-based Model Architecture\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Overall Model Architecture. This figure show the overall structure of the backbone model (non mobile-based model) including DenseNet201, InceptionResNetV2, ResNet50, ResNet152, and NasNetLarge. The detail structure and information can be found at the Apendix A\relax }}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:model-structure}{{6}{7}{Overall Model Architecture. This figure show the overall structure of the backbone model (non mobile-based model) including DenseNet201, InceptionResNetV2, ResNet50, ResNet152, and NasNetLarge. The detail structure and information can be found at the Apendix A\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Overall Mobile-based Model Architecture. This figure show the overall structure of the mobile-based backbone model including MobileNetV2, MobileNetV3Small, MobileNetV3Large, and NasNetMobile. The detail structure and information can be found at the Apendix B\relax }}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:mobile-model-structure}{{7}{8}{Overall Mobile-based Model Architecture. This figure show the overall structure of the mobile-based backbone model including MobileNetV2, MobileNetV3Small, MobileNetV3Large, and NasNetMobile. The detail structure and information can be found at the Apendix B\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Loss Function}{8}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Evaluation Metrics}{8}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confusion Matrix\relax }}{8}{figure.caption.11}\protected@file@percent }
\newlabel{fig:confusion-matrix}{{8}{8}{Confusion Matrix\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Area Under the Curve\relax }}{8}{figure.caption.11}\protected@file@percent }
\newlabel{fig:AUC}{{9}{8}{Area Under the Curve\relax }{figure.caption.11}{}}
\citation{6980}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Traning}{9}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{9}{section.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Accuracy of the model with augmented data\relax }}{9}{table.caption.12}\protected@file@percent }
\newlabel{table:Acc-Augment-Model}{{4}{9}{Accuracy of the model with augmented data\relax }{table.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Accuracy of the model with metadata\relax }}{9}{table.caption.14}\protected@file@percent }
\newlabel{table:Acc-Metadata-Model}{{5}{9}{Accuracy of the model with metadata\relax }{table.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces F1 Score on each class of each model. The class contain AKIEC, BCC, BKL, DF, MEL, NV, VASC which is denoted in the abbreviation section. The models showed in the above bar chart include DenseNet201 and InceoptionResNetV2 which are the two best model after hyper tuning. AD means the two models are trained with augmented data created during the training, there is neither no metadata nor weight loss contribution. \relax }}{10}{figure.caption.15}\protected@file@percent }
\newlabel{fig:f1 AD}{{10}{10}{F1 Score on each class of each model. The class contain AKIEC, BCC, BKL, DF, MEL, NV, VASC which is denoted in the abbreviation section. The models showed in the above bar chart include DenseNet201 and InceoptionResNetV2 which are the two best model after hyper tuning. AD means the two models are trained with augmented data created during the training, there is neither no metadata nor weight loss contribution. \relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The f1-score on each class of two models: DenseNet201 and InceptionResNetV2 which are trained with the MetaData (MD) and the Weight Loss (WL) function. In this case, there is no contribution from the augmented data.The detail architecture of the model can be seen at the appendix section A. The f1-score performance results of other models can be seen at appendix section C.1\relax }}{11}{figure.caption.16}\protected@file@percent }
\newlabel{fig:f1 MD WL}{{11}{11}{The f1-score on each class of two models: DenseNet201 and InceptionResNetV2 which are trained with the MetaData (MD) and the Weight Loss (WL) function. In this case, there is no contribution from the augmented data.The detail architecture of the model can be seen at the appendix section A. The f1-score performance results of other models can be seen at appendix section C.1\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Recall score on each class of each model. The class contain AKIEC, BCC, BKL, DF, MEL, NV, VASC which is denoted in the abbreviation section. The models showed in the above bar chart include DenseNet201 and InceoptionResNetV2 which are the two best model after hyper tuning. AD means the two models are trained with augmented data created during the training, there is neither no metadata nor weight loss contribution. The detail architecture of the model can be seen at the appendix section A. The f1-score performance results of other models can be seen at appendix section C.2\relax }}{11}{figure.caption.17}\protected@file@percent }
\newlabel{fig:re AD}{{12}{11}{Recall score on each class of each model. The class contain AKIEC, BCC, BKL, DF, MEL, NV, VASC which is denoted in the abbreviation section. The models showed in the above bar chart include DenseNet201 and InceoptionResNetV2 which are the two best model after hyper tuning. AD means the two models are trained with augmented data created during the training, there is neither no metadata nor weight loss contribution. The detail architecture of the model can be seen at the appendix section A. The f1-score performance results of other models can be seen at appendix section C.2\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The recall score on each class of two models: DenseNet201 and InceptionResNetV2 which are trained with the MetaData (MD) and the Weight Loss (WL) function. In this case, there is no contribution from the augmented data.The detail architecture of the model can be seen at the appendix section A. The f1-score performance results of other models can be seen at appendix section C.2\relax }}{12}{figure.caption.18}\protected@file@percent }
\newlabel{fig:re MD WL}{{13}{12}{The recall score on each class of two models: DenseNet201 and InceptionResNetV2 which are trained with the MetaData (MD) and the Weight Loss (WL) function. In this case, there is no contribution from the augmented data.The detail architecture of the model can be seen at the appendix section A. The f1-score performance results of other models can be seen at appendix section C.2\relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces How Performance of MobileNetV3Large be optimized\relax }}{12}{table.caption.19}\protected@file@percent }
\newlabel{table:optimized-performance-mobile-model}{{6}{12}{How Performance of MobileNetV3Large be optimized\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions}{12}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix\nobreakspace  {}A}{14}{appendix.A.}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A1}{\ignorespaces Details Structure of Models except Mobile models. SA stands for Soft-Attention, SA Module denotes whether that model use Soft-Attention Module. GAP stands for Global Average Pooling. FC stands for Fully-Connected Layer\relax }}{14}{table.caption.20}\protected@file@percent }
\newlabel{appendix-table:detailed structure model}{{A1}{14}{Details Structure of Models except Mobile models. SA stands for Soft-Attention, SA Module denotes whether that model use Soft-Attention Module. GAP stands for Global Average Pooling. FC stands for Fully-Connected Layer\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Appendix\nobreakspace  {}B}{15}{appendix.B.}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A2}{\ignorespaces Details Structure of Mobile based Models. SA stands for Soft-Attention, SA Module denotes whether that model use Soft-Attention Module. SE which stands for Squeeze-And-Excite shows whether that block has Squeeze-And-Excite. \relax }}{15}{table.caption.21}\protected@file@percent }
\newlabel{appendix-table:detailed mobile model structure}{{A2}{15}{Details Structure of Mobile based Models. SA stands for Soft-Attention, SA Module denotes whether that model use Soft-Attention Module. SE which stands for Squeeze-And-Excite shows whether that block has Squeeze-And-Excite. \relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Appendix\nobreakspace  {}C}{16}{appendix.C.}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Appendix\nobreakspace  {}C}{16}{subsection.C.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A3}{\ignorespaces F1-Score of each class: akiec, bcc, bkl, df, mel, nv, vasc which are denoted in the abbreviation. The last column is the expected value of f1-score from each model. All model in the first column is the models trained in this research. The term "with Augmented Data" means that model is trained with data augmenting during the training, there is no metadata or weight loss contribution. The term "with Metadata and WeightLoss" means that the model is trained with metadata including age, gender, localization and the weight loss function, there is no augmented data contribution\relax }}{16}{table.caption.22}\protected@file@percent }
\newlabel{table:F1-score-summary}{{A3}{16}{F1-Score of each class: akiec, bcc, bkl, df, mel, nv, vasc which are denoted in the abbreviation. The last column is the expected value of f1-score from each model. All model in the first column is the models trained in this research. The term "with Augmented Data" means that model is trained with data augmenting during the training, there is no metadata or weight loss contribution. The term "with Metadata and WeightLoss" means that the model is trained with metadata including age, gender, localization and the weight loss function, there is no augmented data contribution\relax }{table.caption.22}{}}
\citation{04381}
\citation{02244}
\citation{02244}
\citation{07012}
\bibcite{08332}{{1}{year}{{Author1}}{{}}}
\bibcite{03225}{{2}{year}{{Author2}}{{}}}
\bibcite{03798}{{3}{year}{{Author2}}{{}}}
\bibcite{09365}{{4}{year}{{Author2}}{{}}}
\bibcite{10348}{{5}{year}{{Author2}}{{}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Appendix\nobreakspace  {}C}{17}{subsection.C.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A4}{\ignorespaces Recall score of each class and the expected value of recall score from each model\relax }}{17}{table.caption.23}\protected@file@percent }
\newlabel{table:recall-score-summary}{{A4}{17}{Recall score of each class and the expected value of recall score from each model\relax }{table.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Appendix\nobreakspace  {}C}{17}{subsection.C.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A5}{\ignorespaces Deeper analyzing of mobile model. This table illustrate the other indicators of the four mobile-based models including MobileNetV2, MobileNetV3Small, MobileNetV3Large, NasNetMobile. The indicators are Accuracy, Balanced Accuracy, Precision, F1-score, Sensitivity, Specificity, and ROC - AUC score. All of them are average indicator\relax }}{17}{table.caption.24}\protected@file@percent }
\newlabel{table:mobile-performance}{{A5}{17}{Deeper analyzing of mobile model. This table illustrate the other indicators of the four mobile-based models including MobileNetV2, MobileNetV3Small, MobileNetV3Large, NasNetMobile. The indicators are Accuracy, Balanced Accuracy, Precision, F1-score, Sensitivity, Specificity, and ROC - AUC score. All of them are average indicator\relax }{table.caption.24}{}}
\@writefile{toc}{\contentsline {section}{References}{17}{table.caption.24}\protected@file@percent }
\bibcite{06612}{{6}{year}{{Author2}}{{}}}
\bibcite{10417}{{7}{year}{{Author2}}{{}}}
\bibcite{05045}{{8}{year}{{Author2}}{{}}}
\bibcite{09418}{{9}{year}{{Author2}}{{}}}
\bibcite{03910}{{10}{year}{{Author2}}{{}}}
\bibcite{11797}{{11}{year}{{Author2}}{{}}}
\bibcite{01284}{{12}{year}{{Author2}}{{}}}
\bibcite{11872}{{13}{year}{{Author2}}{{}}}
\bibcite{03358}{{14}{year}{{Author2}}{{}}}
\bibcite{12602}{{15}{year}{{Author2}}{{}}}
\bibcite{03426}{{16}{year}{{Author2}}{{}}}
\bibcite{06993}{{17}{year}{{Author2}}{{}}}
\bibcite{11946}{{18}{year}{{Author2}}{{}}}
\bibcite{00567}{{19}{year}{{Author2}}{{}}}
\bibcite{04861}{{20}{year}{{Author2}}{{}}}
\bibcite{04381}{{21}{year}{{Author2}}{{}}}
\bibcite{02244}{{22}{year}{{Author2}}{{}}}
\bibcite{03385}{{23}{year}{{Author2}}{{}}}
\bibcite{05027}{{24}{year}{{Author2}}{{}}}
\bibcite{1556}{{25}{year}{{Author2}}{{}}}
\bibcite{02357}{{26}{year}{{Author2}}{{}}}
\bibcite{6980}{{27}{year}{{Author2}}{{}}}
\bibcite{03044}{{28}{year}{{Author2}}{{}}}
\bibcite{202017}{{29}{year}{{Author2}}{{}}}
\bibcite{08513}{{30}{year}{{Author2}}{{}}}
\bibcite{02357}{{31}{year}{{Author2}}{{}}}
\bibcite{8943952}{{32}{year}{{Author2}}{{}}}
\bibcite{07012}{{33}{year}{{Author2}}{{}}}
\bibcite{08375}{{34}{year}{{Author2}}{{}}}
\bibcite{01507}{{35}{year}{{Author2}}{{}}}
\bibcite{04552v2}{{36}{year}{{Author2}}{{}}}
\bibcite{07261}{{37}{year}{{Author2}}{{}}}
\newlabel{LastPage}{{}{19}{}{page.19}{}}
\xdef\lastpage@lastpage{19}
\xdef\lastpage@lastpageHy{19}
\expandafter\ifx\csname c@page@totc\endcsname\relax\newcounter{page@totc}\fi\setcounter{page@totc}{20}
\gdef \@abspage@last{19}
