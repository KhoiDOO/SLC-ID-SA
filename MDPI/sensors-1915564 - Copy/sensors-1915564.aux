\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{Definitions/mdpi}
\citation{03358}
\citation{03358}
\citation{11872}
\citation{11872}
\citation{11872}
\citation{11797}
\citation{11872}
\newmarginnote{note.1.1}{{1}{10945661sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Problem Statement}{1}{subsection.1.1}\protected@file@percent }
\citation{06993}
\citation{04861}
\citation{00567,07261}
\citation{04861,04381,02244}
\citation{02357}
\citation{03385,05027}
\citation{07012}
\citation{03358}
\citation{03798}
\citation{10348}
\citation{09418}
\citation{01284}
\citation{06612}
\citation{03225}
\citation{12602}
\citation{03426}
\citation{03910}
\citation{05045}
\citation{2101.133}
\citation{22750}
\citation{9445180}
\citation{03358}
\citation{06993}
\citation{00567}
\citation{03385,05027}
\citation{1556}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Related Works}{2}{subsection.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces {Summary of related} works.\relax }}{2}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table:related-work-summary}{{1}{2}{{Summary of related} works.\relax }{table.caption.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Deep Learning Approach}{2}{subsubsection.1.2.1}\protected@file@percent }
\citation{03798}
\citation{2101.133}
\citation{10348}
\citation{00567}
\citation{09418}
\citation{11946}
\citation{01507}
\citation{04552v2}
\citation{01284}
\citation{06612}
\citation{03225}
\citation{12602}
\citation{03426}
\citation{03910}
\citation{22750}
\citation{03798}
\citation{09365}
\citation{05045}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Machine Learning Approach}{4}{subsubsection.1.2.2}\protected@file@percent }
\citation{10417}
\citation{10417}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Proposed Method}{5}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Materials and Methods}{5}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Materials}{5}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Image Data}{5}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Data distribution in HAM10000.\relax }}{5}{table.caption.2}\protected@file@percent }
\newlabel{table:data-distribution}{{2}{5}{Data distribution in HAM10000.\relax }{table.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces {Example} image of each class.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:data-sample}{{1}{5}{{Example} image of each class.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Metadata}{5}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces {Metadata} example in the data set.\relax }}{5}{table.caption.4}\protected@file@percent }
\newlabel{table:metadata sample}{{3}{5}{{Metadata} example in the data set.\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Methodology}{6}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Overall Architecture}{6}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Overall model architecture.\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:main-model}{{2}{6}{Overall model architecture.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces {Proposed} backbone model architecture. This figure show the overall structure of the backbone model (non mobile-based model) including DenseNet201, InceptionResNetV2, ResNet50, ResNet152, and NasNetLarge {with Soft-Attention}. The detailed structure and information can be found in the Appendix \ref {appendix-table:detailed structure model}.\relax }}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:model-structure}{{3}{6}{{Proposed} backbone model architecture. This figure show the overall structure of the backbone model (non mobile-based model) including DenseNet201, InceptionResNetV2, ResNet50, ResNet152, and NasNetLarge {with Soft-Attention}. The detailed structure and information can be found in the Appendix \ref {appendix-table:detailed structure model}.\relax }{figure.caption.6}{}}
\citation{2012.4305}
\citation{06993}
\citation{03385,05027}
\citation{11946}
\citation{04861,04381,02244}
\citation{07012}
\citation{03910}
\citation{08375}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces {Mobile-based} backbone model architecture. This figure shows the overall structure of the mobile-based backbone model including MobileNetV2, MobileNetV3Small, MobileNetV3Large, and NasNetMobile. The detailed structure and information can be found in the Appendix \ref {appendix-table:detailed mobile model structure}.\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:mobile-model-structure}{{4}{7}{{Mobile-based} backbone model architecture. This figure shows the overall structure of the mobile-based backbone model including MobileNetV2, MobileNetV3Small, MobileNetV3Large, and NasNetMobile. The detailed structure and information can be found in the Appendix \ref {appendix-table:detailed mobile model structure}.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Input Schema}{7}{subsubsection.2.2.2}\protected@file@percent }
\citation{06993}
\citation{00567}
\citation{04861,04381,02244}
\citation{03385,05027}
\citation{07012}
\citation{03358}
\citation{03044}
\citation{202017}
\citation{08513}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Input schema.\relax }}{8}{figure.caption.8}\protected@file@percent }
\newlabel{fig:input-schema}{{5}{8}{Input schema.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Backbone Model}{8}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces {Size}, parameters, and depth of the backbone model used in this paper.\relax }}{8}{table.caption.9}\protected@file@percent }
\newlabel{table:model-summary}{{4}{8}{{Size}, parameters, and depth of the backbone model used in this paper.\relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Soft-Attention Module}{8}{subsubsection.2.2.4}\protected@file@percent }
\newlabel{eqn:softatt}{{1}{8}{Soft-Attention Module}{equation.2.1}{}}
\citation{03358}
\citation{8943952}
\citation{WV006-01}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces {Soft-Attention layer.} \relax }}{9}{figure.caption.10}\protected@file@percent }
\newlabel{fig:soft-attention}{{6}{9}{{Soft-Attention layer.} \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces {Soft-Attention module.} \relax }}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:soft-attention-block}{{7}{9}{{Soft-Attention module.} \relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Loss Function}{9}{subsubsection.2.2.5}\protected@file@percent }
\newlabel{eqn:weightlossfunction}{{2}{9}{Loss Function}{equation.2.2}{}}
\citation{6980}
\newlabel{eqn:weightformula}{{3}{10}{Loss Function}{equation.2.3}{}}
\newlabel{eqn:vector-inverse-percent}{{4}{10}{Loss Function}{equation.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{10}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Experimental Setup}{10}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Training}{10}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Tools}{10}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Evaluation Metrics}{10}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confusion matrix.\relax }}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:confusion-matrix}{{8}{11}{Confusion matrix.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces {Area} under the curve.\relax }}{11}{figure.caption.13}\protected@file@percent }
\newlabel{fig:AUC}{{9}{11}{{Area} under the curve.\relax }{figure.caption.13}{}}
\newlabel{eqn:FP}{{5}{11}{Evaluation Metrics}{equation.3.5}{}}
\newlabel{eqn:FN}{{6}{11}{Evaluation Metrics}{equation.3.6}{}}
\newlabel{eqn:TN}{{7}{11}{Evaluation Metrics}{equation.3.7}{}}
\newlabel{eqn:sens}{{8}{11}{Evaluation Metrics}{equation.3.8}{}}
\newlabel{eqn:spec}{{9}{12}{Evaluation Metrics}{equation.3.9}{}}
\newlabel{eqn:pre}{{10}{12}{Evaluation Metrics}{equation.3.10}{}}
\newlabel{eqn:f1}{{11}{12}{Evaluation Metrics}{equation.3.11}{}}
\newlabel{eqn:acc}{{12}{12}{Evaluation Metrics}{equation.3.12}{}}
\newlabel{eqn:balacc}{{13}{12}{Evaluation Metrics}{equation.3.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Discussion}{12}{subsection.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Accuracy of all models. ACC stands for accuracy. AD stands for augmented data; this indicates that the model is trained with augmented data. MD stands for metadata, which indicates that the model is trained with metadata. The bold numbers highlight the highest performance.\relax }}{13}{table.caption.14}\protected@file@percent }
\newlabel{table:overall-acc}{{5}{13}{Accuracy of all models. ACC stands for accuracy. AD stands for augmented data; this indicates that the model is trained with augmented data. MD stands for metadata, which indicates that the model is trained with metadata. The bold numbers highlight the highest performance.\relax }{table.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces {DenseNet201} confusion matrix.\relax }}{13}{figure.caption.15}\protected@file@percent }
\newlabel{fig:densenet201cm}{{10}{13}{{DenseNet201} confusion matrix.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces {InceptionResNetV2} confusion matrix.\relax }}{14}{figure.caption.16}\protected@file@percent }
\newlabel{fig:irv2cm}{{11}{14}{{InceptionResNetV2} confusion matrix.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The comparison between F1-scores of DenseNet201 trained with augmented data and the one trained with metadata and weight loss.\relax }}{14}{figure.caption.17}\protected@file@percent }
\newlabel{fig:den f1}{{12}{14}{The comparison between F1-scores of DenseNet201 trained with augmented data and the one trained with metadata and weight loss.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The comparison between F1-scores of InceptionResNetV2 trained with augmented data and the one trained with metadata and weight loss.\relax }}{15}{figure.caption.18}\protected@file@percent }
\newlabel{fig:incep f1}{{13}{15}{The comparison between F1-scores of InceptionResNetV2 trained with augmented data and the one trained with metadata and weight loss.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The comparison between recall of DenseNet201 trained with augmented data and the one trained with metadata and weight loss.\relax }}{15}{figure.caption.19}\protected@file@percent }
\newlabel{fig:den recall}{{14}{15}{The comparison between recall of DenseNet201 trained with augmented data and the one trained with metadata and weight loss.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Comparison between recall of InceptionResNetV2 trained with augmented data and the one trained with metadata and weight loss.\relax }}{16}{figure.caption.20}\protected@file@percent }
\newlabel{fig:incep recall}{{15}{16}{Comparison between recall of InceptionResNetV2 trained with augmented data and the one trained with metadata and weight loss.\relax }{figure.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces {Comparison between MobileNetV3Large with DenseNet201 and InceptionResNetV2.}\relax }}{16}{table.caption.21}\protected@file@percent }
\newlabel{table:optimized-performance-mobile-model}{{6}{16}{{Comparison between MobileNetV3Large with DenseNet201 and InceptionResNetV2.}\relax }{table.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces AUCs of all models. AD stands for augmented data, this indicates that the model is trained with augmented data. MD stands for metadata, which indicates that the model is trained with metadata. Bold numbers highlight the highest performance\relax }}{17}{table.caption.22}\protected@file@percent }
\newlabel{table:overall-auc}{{7}{17}{AUCs of all models. AD stands for augmented data, this indicates that the model is trained with augmented data. MD stands for metadata, which indicates that the model is trained with metadata. Bold numbers highlight the highest performance\relax }{table.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces ROC of DenseNet201 and InceptionResNetV2.\relax }}{17}{figure.caption.23}\protected@file@percent }
\newlabel{fig:densevsirv2}{{16}{17}{ROC of DenseNet201 and InceptionResNetV2.\relax }{figure.caption.23}{}}
\citation{03358}
\citation{03798}
\citation{09418}
\citation{01284}
\citation{06612}
\citation{03225}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Loss-based model accuracy comparison.\relax }}{18}{table.caption.24}\protected@file@percent }
\newlabel{table:loss-comparision}{{8}{18}{Loss-based model accuracy comparison.\relax }{table.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Comparative Analysis. Bold numbers highlight the highest performance.\relax }}{18}{table.caption.25}\protected@file@percent }
\newlabel{table:comparative-analysis}{{9}{18}{Comparative Analysis. Bold numbers highlight the highest performance.\relax }{table.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Model ability to classify melanoma and nevus.\relax }}{19}{figure.caption.26}\protected@file@percent }
\newlabel{fig:nevusVSmela}{{17}{19}{Model ability to classify melanoma and nevus.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions}{19}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix\nobreakspace  {}A}{21}{appendix.A.}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A1}{\ignorespaces {Detailed structure} of models except for mobile models. SA stands for Soft-Attention, SA Module denotes whether that model uses the Soft-Attention module. GAP stands for Global Average Pooling. FC stands for Fully Connected Layer.\relax }}{21}{table.caption.27}\protected@file@percent }
\newlabel{appendix-table:detailed structure model}{{A1}{21}{{Detailed structure} of models except for mobile models. SA stands for Soft-Attention, SA Module denotes whether that model uses the Soft-Attention module. GAP stands for Global Average Pooling. FC stands for Fully Connected Layer.\relax }{table.caption.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Appendix\nobreakspace  {}B}{22}{appendix.B.}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A2}{\ignorespaces {Detailed} structure of mobile-based models. SA stands for Soft-Attention, SA Module denotes whether that model uses the Soft-Attention module. SE which stands for Squeeze-And-Excite, and it shows whether that block has Squeeze-And-Excite. \relax }}{22}{table.caption.28}\protected@file@percent }
\newlabel{appendix-table:detailed mobile model structure}{{A2}{22}{{Detailed} structure of mobile-based models. SA stands for Soft-Attention, SA Module denotes whether that model uses the Soft-Attention module. SE which stands for Squeeze-And-Excite, and it shows whether that block has Squeeze-And-Excite. \relax }{table.caption.28}{}}
\citation{04381}
\citation{02244}
\citation{02244}
\citation{07012}
\@writefile{toc}{\contentsline {section}{\numberline {C}Appendix\nobreakspace  {}C}{23}{appendix.C.}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Appendix\nobreakspace  {}C}{23}{subsection.C.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A3}{\ignorespaces {F1-score} of each class: akiec, bcc, bkl, df, mel, nv and vasc, which are denoted in the abbreviations. The last column shows the expected value of the F1-score from each model. All models in the first column are the models trained in this research. The term “with Augmented Data” means that model is trained with data augmenting during the training, there is no metadata or weight loss contribution. The term “with Metadata and WeightLoss” means that the model is trained with metadata including age, gender, localization, and the weight loss function, there is no augmented data contribution. {Besides the bold number highlights achievement of the research}\relax }}{23}{table.caption.29}\protected@file@percent }
\newlabel{appendix-table:F1-score-summary}{{A3}{23}{{F1-score} of each class: akiec, bcc, bkl, df, mel, nv and vasc, which are denoted in the abbreviations. The last column shows the expected value of the F1-score from each model. All models in the first column are the models trained in this research. The term “with Augmented Data” means that model is trained with data augmenting during the training, there is no metadata or weight loss contribution. The term “with Metadata and WeightLoss” means that the model is trained with metadata including age, gender, localization, and the weight loss function, there is no augmented data contribution. {Besides the bold number highlights achievement of the research}\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Appendix\nobreakspace  {}C}{23}{subsection.C.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A4}{\ignorespaces {Recall} of each class and the expected value of recall from each model.\relax }}{23}{table.caption.30}\protected@file@percent }
\newlabel{appendix-table:recall-score-summary}{{A4}{23}{{Recall} of each class and the expected value of recall from each model.\relax }{table.caption.30}{}}
\bibcite{03358}{{1}{year}{{Author2}}{{}}}
\bibcite{11872}{{2}{year}{{Author2}}{{}}}
\bibcite{11797}{{3}{year}{{Author2}}{{}}}
\bibcite{06993}{{4}{year}{{Author2}}{{}}}
\bibcite{04861}{{5}{year}{{Author2}}{{}}}
\bibcite{00567}{{6}{year}{{Author2}}{{}}}
\bibcite{07261}{{7}{year}{{Author2}}{{}}}
\bibcite{04381}{{8}{year}{{Author2}}{{}}}
\bibcite{02244}{{9}{year}{{Author2}}{{}}}
\bibcite{02357}{{10}{year}{{Author2}}{{}}}
\bibcite{03385}{{11}{year}{{Author2}}{{}}}
\bibcite{05027}{{12}{year}{{Author2}}{{}}}
\bibcite{07012}{{13}{year}{{Author2}}{{}}}
\bibcite{03798}{{14}{year}{{Author2}}{{}}}
\bibcite{10348}{{15}{year}{{Author2}}{{}}}
\bibcite{09418}{{16}{year}{{Author2}}{{}}}
\bibcite{01284}{{17}{year}{{Author2}}{{}}}
\bibcite{06612}{{18}{year}{{Author2}}{{}}}
\bibcite{03225}{{19}{year}{{Author2}}{{}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Appendix\nobreakspace  {}C}{24}{subsection.C.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A5}{\ignorespaces {Deeper} analyzing of the mobile model. This table illustrates the other indicators of the four mobile-based models including MobileNetV2, MobileNetV3Small, MobileNetV3Large, and NasNetMobile. The indicators are Accuracy, Balanced Accuracy, Precision, F1-score, Sensitivity, Specificity, and AUC. All of them are average indicators.\relax }}{24}{table.caption.31}\protected@file@percent }
\newlabel{appendix-table:mobile-performance}{{A5}{24}{{Deeper} analyzing of the mobile model. This table illustrates the other indicators of the four mobile-based models including MobileNetV2, MobileNetV3Small, MobileNetV3Large, and NasNetMobile. The indicators are Accuracy, Balanced Accuracy, Precision, F1-score, Sensitivity, Specificity, and AUC. All of them are average indicators.\relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {section}{References}{24}{table.caption.31}\protected@file@percent }
\bibcite{12602}{{20}{year}{{Author2}}{{}}}
\bibcite{03426}{{21}{year}{{Author2}}{{}}}
\bibcite{03910}{{22}{year}{{Author2}}{{}}}
\bibcite{05045}{{23}{year}{{Author2}}{{}}}
\bibcite{2101.133}{{24}{year}{{Author2}}{{}}}
\bibcite{22750}{{25}{year}{{Author2}}{{}}}
\bibcite{9445180}{{26}{year}{{Author2}}{{}}}
\bibcite{1556}{{27}{year}{{Author2}}{{}}}
\bibcite{11946}{{28}{year}{{Author2}}{{}}}
\bibcite{01507}{{29}{year}{{Author2}}{{}}}
\bibcite{04552v2}{{30}{year}{{Author2}}{{}}}
\bibcite{09365}{{31}{year}{{Author2}}{{}}}
\bibcite{10417}{{32}{year}{{Author2}}{{}}}
\bibcite{2012.4305}{{33}{year}{{Author2}}{{}}}
\bibcite{08375}{{34}{year}{{Author2}}{{}}}
\bibcite{03044}{{35}{year}{{Author2}}{{}}}
\bibcite{202017}{{36}{year}{{Author2}}{{}}}
\bibcite{08513}{{37}{year}{{Author2}}{{}}}
\bibcite{8943952}{{38}{year}{{Author2}}{{}}}
\bibcite{WV006-01}{{39}{year}{{Author2}}{{}}}
\bibcite{6980}{{40}{year}{{Author2}}{{}}}
\bibcite{02357-1}{{41}{year}{{Author2}}{{}}}
\newlabel{LastPage}{{}{25}{}{page.25}{}}
\xdef\lastpage@lastpage{25}
\xdef\lastpage@lastpageHy{25}
\expandafter\ifx\csname c@page@totc\endcsname\relax\newcounter{page@totc}\fi\setcounter{page@totc}{26}
\gdef \@abspage@last{25}
