{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5X3ASNLkv3Y",
    "outputId": "08716771-3835-4047-d33b-20f4c701ad4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTi0RAUGEfoM",
    "outputId": "248856e8-5245-478f-ae27-2c61126927a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "filename=\"/content/drive/My Drive/HAM10000.zip\"\n",
    "with ZipFile(filename,'r') as zip:\n",
    "  zip.extractall()\n",
    "  print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Aa36bMKLze3z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import callbacks \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from  matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lnzRzk7e44HL",
    "outputId": "610769db-4176-4360-accb-e32c86d316da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv('/content/drive/MyDrive/HAM10000_metadata.csv')\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qlR6SjeEzXsm"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join('HAM10000', 'train_dir')\n",
    "test_dir = os.path.join('HAM10000', 'test_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "_IFqPgUu5jPj",
    "outputId": "3d3945d6-745f-44c2-8f5c-6a3bb1d670f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lesion_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HAM_0000000</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000001</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000002</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAM_0000004</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  dx  dx_type  age  sex  localization\n",
       "lesion_id                                                 \n",
       "HAM_0000000         2   2        2    2    2             2\n",
       "HAM_0000001         1   1        1    1    1             1\n",
       "HAM_0000002         3   3        3    3    3             3\n",
       "HAM_0000003         1   1        1    1    1             1\n",
       "HAM_0000004         1   1        1    1    1             1"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = data_pd.groupby('lesion_id').count()\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QjMQNZRI2xl7"
   },
   "outputs": [],
   "source": [
    "df_count = df_count[df_count['dx'] == 1]\n",
    "df_count.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NeVfs-Ly95gs"
   },
   "outputs": [],
   "source": [
    "def duplicates(x):\n",
    "    unique = set(df_count['lesion_id'])\n",
    "    if x in unique:\n",
    "        return 'no' \n",
    "    else:\n",
    "        return 'duplicates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2WZZRSzO5v8t",
    "outputId": "d0abab3d-4e4e-419f-e914-4f32b52c9346"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>duplicates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization is_duplicate\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   duplicates\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   duplicates\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   duplicates\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   duplicates\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   duplicates"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd['is_duplicate'] = data_pd['lesion_id'].apply(duplicates)\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3BhGlAv0yAHu"
   },
   "outputs": [],
   "source": [
    "df_count = data_pd[data_pd['is_duplicate'] == 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y3ndAO_Ex5fb"
   },
   "outputs": [],
   "source": [
    "train, test_df = train_test_split(df_count, test_size=0.2, stratify=df_count['dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T7w2kYUdNkjX",
    "outputId": "c0a3690c-af1e-4828-f620-36be5cc685a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>train_test_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx  ... localization  is_duplicate train_test_split\n",
       "0  HAM_0000118  ISIC_0027419  bkl  ...        scalp    duplicates            train\n",
       "1  HAM_0000118  ISIC_0025030  bkl  ...        scalp    duplicates            train\n",
       "2  HAM_0002730  ISIC_0026769  bkl  ...        scalp    duplicates            train\n",
       "3  HAM_0002730  ISIC_0025661  bkl  ...        scalp    duplicates            train\n",
       "4  HAM_0001466  ISIC_0031633  bkl  ...          ear    duplicates            train\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identify_trainOrtest(x):\n",
    "    test_data = set(test_df['image_id'])\n",
    "    if str(x) in test_data:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "#creating train_df\n",
    "data_pd['train_test_split'] = data_pd['image_id'].apply(identify_trainOrtest)\n",
    "train_df = data_pd[data_pd['train_test_split'] == 'train']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FPySEG1m58pu",
    "outputId": "b03fffa8-9ada-4721-964c-a74ea574f6a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>HAM_0004766</td>\n",
       "      <td>ISIC_0030462</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>HAM_0001222</td>\n",
       "      <td>ISIC_0029916</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>HAM_0001167</td>\n",
       "      <td>ISIC_0028448</td>\n",
       "      <td>bkl</td>\n",
       "      <td>consensus</td>\n",
       "      <td>55.0</td>\n",
       "      <td>male</td>\n",
       "      <td>trunk</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>HAM_0005356</td>\n",
       "      <td>ISIC_0028854</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>HAM_0005909</td>\n",
       "      <td>ISIC_0026045</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id      image_id     dx  ...   sex     localization is_duplicate\n",
       "7129  HAM_0004766  ISIC_0030462     nv  ...  male            trunk           no\n",
       "6340  HAM_0001222  ISIC_0029916     nv  ...  male             back           no\n",
       "1022  HAM_0001167  ISIC_0028448    bkl  ...  male            trunk           no\n",
       "9766  HAM_0005356  ISIC_0028854  akiec  ...  male             face           no\n",
       "2253  HAM_0005909  ISIC_0026045    mel  ...  male  upper extremity           no\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ja7jQJQb39wi"
   },
   "outputs": [],
   "source": [
    "# Image id of train and test images\n",
    "train_list = list(train_df['image_id'])\n",
    "test_list = list(test_df['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBJgBAjP13q5",
    "outputId": "0da1470c-3c8a-45b2-b45a-94d6e0b3a1ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEChk1DK-H8Z",
    "outputId": "0249d682-1b00-4e7c-b91c-8e6a13ddb7ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8912"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PIoMqylGAYYZ"
   },
   "outputs": [],
   "source": [
    "# Set the image_id as the index in data_pd\n",
    "data_pd.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ja_PtDYyDPMM"
   },
   "outputs": [],
   "source": [
    "os.mkdir(train_dir)\n",
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PsoqCvNsgmHP"
   },
   "outputs": [],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9KYMTQugCmRR"
   },
   "outputs": [],
   "source": [
    "for i in targetnames:\n",
    "  directory1=train_dir+'/'+i\n",
    "  directory2=test_dir+'/'+i\n",
    "  os.mkdir(directory1)\n",
    "  os.mkdir(directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GL9vFa3X-ty1"
   },
   "outputs": [],
   "source": [
    "for image in train_list:\n",
    "    file_name = image+'.jpg'\n",
    "    label = data_pd.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join('HAM10000', file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(train_dir, label, file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hwbKrEzJ_if2"
   },
   "outputs": [],
   "source": [
    "for image in test_list:\n",
    "\n",
    "    file_name = image+'.jpg'\n",
    "    label = data_pd.loc[image, 'dx']\n",
    "\n",
    "    # path of source image \n",
    "    source = os.path.join('HAM10000', file_name)\n",
    "\n",
    "    # copying the image from the source to target file\n",
    "    target = os.path.join(test_dir, label, file_name)\n",
    "\n",
    "    shutil.copyfile(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4W8hmE2OHjQa",
    "outputId": "fdeaca8b-1b24-41eb-82b5-68855d2734cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 297 images belonging to 1 classes.\n",
      "Found 479 images belonging to 1 classes.\n",
      "Found 1011 images belonging to 1 classes.\n",
      "Found 107 images belonging to 1 classes.\n",
      "Found 1067 images belonging to 1 classes.\n",
      "Found 5822 images belonging to 1 classes.\n",
      "Found 129 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "\n",
    "# Augmenting images and storing them in temporary directories \n",
    "for img_class in targetnames:\n",
    "\n",
    "    #creating temporary directories\n",
    "    # creating a base directory\n",
    "    aug_dir = 'aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    # creating a subdirectory inside the base directory for images of the same class\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    img_list = os.listdir('HAM10000/train_dir/' + img_class)\n",
    "\n",
    "    # Copy images from the class train dir to the img_dir \n",
    "    for file_name in img_list:\n",
    "\n",
    "        # path of source image in training directory\n",
    "        source = os.path.join('HAM10000/train_dir/' + img_class, file_name)\n",
    "\n",
    "        # creating a target directory to send images \n",
    "        target = os.path.join(img_dir, file_name)\n",
    "\n",
    "        # copying the image from the source to target file\n",
    "        shutil.copyfile(source, target)\n",
    "\n",
    "    # Temporary augumented dataset directory.\n",
    "    source_path = aug_dir\n",
    "\n",
    "    # Augmented images will be saved to training directory\n",
    "    save_path = 'HAM10000/train_dir/' + img_class\n",
    "\n",
    "    # Creating Image Data Generator to augment images\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "\n",
    "    )\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(source_path,save_to_dir=save_path,save_format='jpg',target_size=(299, 299),batch_size=batch_size)\n",
    "\n",
    "    # Generate the augmented images\n",
    "    aug_images = 8000 \n",
    "\n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((aug_images - num_files) / batch_size))\n",
    "\n",
    "    # creating 8000 augmented images per class\n",
    "    for i in range(0, num_batches):\n",
    "        images, labels = next(aug_datagen)\n",
    "\n",
    "    # delete temporary directory \n",
    "    shutil.rmtree('aug_dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wNisha_gM3_Z"
   },
   "outputs": [],
   "source": [
    "train_path = 'HAM10000/train_dir'\n",
    "test_path = 'HAM10000/test_dir'\n",
    "batch_size= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zhQWqdRN79B3"
   },
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9_8FvOO7Rtu",
    "outputId": "fec46cf6-3e44-422d-d96c-7b524c92350f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Batches: \n",
      "Found 52012 images belonging to 7 classes.\n",
      "\n",
      "Test Batches: \n",
      "Found 1103 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 299\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AbwfHcsOPKYB"
   },
   "outputs": [],
   "source": [
    "#Soft Attention\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "class SoftAttention(Layer):\n",
    "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
    "        self.channels=int(ch)\n",
    "        self.multiheads = m\n",
    "        self.aggregate_channels = aggregate\n",
    "        self.concat_input_with_scaled = concat_with_x\n",
    "\n",
    "        \n",
    "        super(SoftAttention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.i_shape = input_shape\n",
    "\n",
    "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
    "    \n",
    "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "\n",
    "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
    "        else:\n",
    "            if self.concat_input_with_scaled:\n",
    "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
    "            else:\n",
    "                self.out_features_shape = input_shape\n",
    "        \n",
    "\n",
    "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
    "                                        initializer='he_uniform',\n",
    "                                        name='kernel_conv3d')\n",
    "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_conv3d')\n",
    "\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        exp_x = K.expand_dims(x,axis=-1)\n",
    "\n",
    "        c3d = K.conv3d(exp_x,\n",
    "                     kernel=self.kernel_conv3d,\n",
    "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
    "        conv3d = K.bias_add(c3d,\n",
    "                        self.bias_conv3d)\n",
    "        conv3d = kl.Activation('relu')(conv3d)\n",
    "\n",
    "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
    "\n",
    "        \n",
    "        conv3d = K.squeeze(conv3d, axis=-1)\n",
    "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
    "\n",
    "        softmax_alpha = K.softmax(conv3d, axis=-1) \n",
    "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
    "\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)       \n",
    "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
    "   \n",
    "            x_exp = K.expand_dims(x,axis=-2)\n",
    "   \n",
    "            u = kl.Multiply()([exp_softmax_alpha, x_exp])   \n",
    "  \n",
    "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
    "\n",
    "        else:\n",
    "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
    "\n",
    "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
    "\n",
    "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
    "\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x])   \n",
    "\n",
    "        if self.concat_input_with_scaled:\n",
    "            o = kl.Concatenate(axis=-1)([u,x])\n",
    "        else:\n",
    "            o = u\n",
    "        \n",
    "        return [o, softmax_alpha]\n",
    "\n",
    "    def compute_output_shape(self, input_shape): \n",
    "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
    "\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(SoftAttention,self).get_config()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrlJwba5By1A",
    "outputId": "b478695c-3419-46bf-9416-f1325c0475c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "225214464/225209952 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "irv2 = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classifier_activation=\"softmax\",\n",
    "\n",
    ")\n",
    "\n",
    "# Excluding the last 28 layers of the model.\n",
    "conv = irv2.layers[-28].output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTFfWfqXVjsf"
   },
   "source": [
    "Soft Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exrVTX_uVYPi"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R13YR5JxVpOg"
   },
   "outputs": [],
   "source": [
    "\n",
    "output = Flatten()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=irv2.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clgALKTDkVC_",
    "outputId": "512d93d1-885e-4adf-a90d-23a06a322d90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 96)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 96)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 48)   13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 48)   144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 64)   27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 48)   13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 48)   13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 48)   144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 48)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 64)   27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 64)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 48)   13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 35, 35, 48)   144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 48)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 64)   27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 35, 35, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 48)   13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 35, 35, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 35, 35, 48)   144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 48)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 32)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 64)   27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 35, 35, 32)   96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 64)   192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 35, 35, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 35, 35, 48)   13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 35, 35, 48)   144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 35, 35, 48)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 32)   9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 64)   27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 35, 35, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 35, 35, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 35, 35, 64)   192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 35, 35, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 35, 35, 48)   13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 35, 35, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 35, 35, 48)   144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 35, 35, 48)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 35, 35, 32)   9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 35, 35, 64)   27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 35, 35, 32)   96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 35, 35, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 35, 35, 64)   192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 32)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 35, 35, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 35, 35, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 35, 35, 48)   13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 35, 35, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 35, 35, 48)   144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 35, 35, 48)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 32)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 35, 35, 64)   27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 35, 35, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 35, 35, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 35, 35, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 35, 35, 32)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 35, 35, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 35, 35, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 35, 35, 48)   13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 35, 35, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 35, 35, 48)   144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 35, 35, 48)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 35, 35, 32)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 35, 35, 64)   27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 35, 35, 32)   96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 35, 35, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 35, 35, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 35, 35, 32)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 35, 35, 64)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 35, 35, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 35, 35, 48)   13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 35, 35, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 35, 35, 48)   144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 35, 35, 48)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 35, 35, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 35, 35, 64)   27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 35, 35, 32)   96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 35, 35, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 35, 35, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 35, 35, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 35, 35, 64)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 35, 35, 256)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 35, 35, 256)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 35, 35, 256)  589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 35, 35, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 384)  884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 384)  1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 384)  1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 384)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 384)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 160)  143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 160)  480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 160)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 192)  215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 192)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 192)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 128)  384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 128)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 160)  143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 160)  480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 160)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 192)  215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 192)  576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 192)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 128)  384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 128)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 160)  143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 160)  480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 160)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 192)  215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 192)  576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 192)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 128)  384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 128)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 160)  143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 160)  480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 160)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 192)  215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 192)  576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 192)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 128)  384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 128)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 160)  143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 160)  480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 160)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 192)  215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 192)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 17, 17, 128)  384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 128)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 160)  143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 17, 17, 160)  480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 160)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 192)  215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 17, 17, 128)  384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 17, 17, 128)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 160)  143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 17, 17, 160)  480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 160)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 192)  215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 17, 17, 192)  576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 17, 17, 192)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 17, 17, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 128)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 160)  143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 17, 17, 160)  480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 17, 17, 160)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 192)  215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 17, 17, 192)  576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 17, 17, 192)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 17, 17, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 17, 17, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 160)  143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 17, 17, 160)  480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 17, 17, 160)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 192)  215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 17, 17, 192)  576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 17, 17, 192)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 17, 17, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 17, 17, 128)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 17, 17, 160)  143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 17, 17, 160)  480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 17, 17, 160)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 17, 17, 192)  215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 17, 17, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 17, 17, 192)  576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 17, 17, 192)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 17, 17, 128)  384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 17, 17, 128)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 17, 17, 160)  143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 17, 17, 160)  480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 17, 17, 160)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 17, 17, 192)  215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 17, 17, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 17, 17, 192)  576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 17, 17, 192)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 17, 17, 128)  384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 17, 17, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 17, 17, 160)  143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 17, 17, 160)  480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 17, 17, 160)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 17, 17, 192)  215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 17, 17, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 17, 17, 192)  576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 17, 17, 192)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 17, 17, 160)  143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 17, 17, 160)  480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 17, 17, 160)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 17, 17, 192)  215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 17, 17, 160)  143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 17, 17, 160)  480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 17, 17, 160)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 17, 17, 192)  215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 17, 17, 192)  576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 17, 17, 192)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 17, 17, 128)  384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 17, 17, 128)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 17, 17, 160)  143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 17, 17, 160)  480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 17, 17, 160)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 17, 17, 192)  215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 17, 17, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 17, 17, 192)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 17, 17, 128)  384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 17, 17, 128)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 17, 17, 160)  143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 17, 17, 192)  215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 17, 17, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 17, 17, 192)  576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 17, 17, 192)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 17, 17, 128)  384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 17, 17, 128)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 17, 17, 160)  143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 17, 17, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 17, 17, 160)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 17, 17, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 17, 17, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 17, 17, 128)  384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 17, 17, 128)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 17, 17, 160)  143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 17, 17, 128)  384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 17, 17, 128)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 17, 17, 160)  143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 17, 17, 192)  215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 17, 17, 192)  576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 17, 17, 192)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 17, 17, 128)  384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 17, 17, 128)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 17, 17, 160)  143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 17, 17, 160)  480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 17, 17, 160)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 17, 17, 192)  215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 17, 17, 256)  768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 17, 17, 256)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 17, 17, 288)  663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 17, 17, 256)  768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 17, 17, 256)  768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 17, 17, 288)  864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 17, 17, 256)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 17, 17, 256)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 17, 17, 288)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 8, 8, 384)    884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 8, 8, 288)    663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 8, 8, 320)    829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 8, 8, 384)    1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 8, 8, 288)    864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 8, 8, 320)    960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 8, 8, 384)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 8, 8, 288)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 8, 8, 320)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 8, 8, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 224)    129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 8, 8, 224)    672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 224)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 256)    172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 8, 8, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 256)    768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 8, 8, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 256)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 8, 8, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 224)    129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 224)    672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 224)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 256)    172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 256)    768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 256)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 8, 8, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 224)    129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 8, 8, 224)    672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 224)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 256)    172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 8, 8, 192)    576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 8, 8, 256)    768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 192)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 256)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 8, 8, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 224)    129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 8, 8, 224)    672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 224)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 256)    172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 8, 8, 192)    576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 8, 8, 256)    768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 192)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 256)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 8, 8, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 224)    129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 8, 8, 224)    672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 8, 8, 224)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 256)    172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 8, 8, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 8, 8, 256)    768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 256)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 8, 8, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 224)    129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 8, 8, 224)    672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 224)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 256)    172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 8, 8, 192)    576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 256)    768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 192)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 256)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 8, 8, 224)    129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 8, 8, 224)    672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 224)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 8, 8, 256)    172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 8, 8, 256)    768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 8, 8, 256)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 8, 8, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 8, 8, 224)    129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 8, 8, 224)    672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 8, 8, 224)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 8, 8, 256)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 8, 8, 192)    576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 8, 8, 256)    768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 8, 8, 192)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 8, 8, 256)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 8, 8, 192)    576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "soft_attention (SoftAttention)  [(None, 8, 8, 192),  27664       batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 192)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 192)    0           soft_attention[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4, 4, 384)    0           max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 4, 4, 384)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4, 4, 384)    0           activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6144)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 7)            43015       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,535,287\n",
      "Trainable params: 47,480,887\n",
      "Non-trainable params: 54,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WR0fUpy18vAZ"
   },
   "outputs": [],
   "source": [
    "opt1=tf.keras.optimizers.Adam(learning_rate=0.01,epsilon=0.1)\n",
    "model.compile(optimizer=opt1,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAf5ha295reS"
   },
   "outputs": [],
   "source": [
    "class_weights = {   \n",
    "                    0: 1.0,  # akiec\n",
    "                    1: 1.0,  # bcc\n",
    "                    2: 1.0,  # bkl\n",
    "                    3: 1.0,  # df\n",
    "                    4: 5.0,  # mel\n",
    "                    5: 1.0,  # nv\n",
    "                    6: 1.0,  # vasc\n",
    "                }\n",
    "\n",
    "\n",
    "checkpoint=  ModelCheckpoint(filepath = 'saved_model.hdf5',monitor='val_accuracy',save_best_only=True,save_weights_only=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUzTmiZ-8hL3",
    "outputId": "081163f7-5194-438b-89c3-a7f91c5a7fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "892/892 - 267s - loss: 2.3642 - accuracy: 0.3649 - val_loss: 0.9736 - val_accuracy: 0.6682\n",
      "Epoch 2/150\n",
      "892/892 - 244s - loss: 1.7796 - accuracy: 0.4650 - val_loss: 0.7679 - val_accuracy: 0.7035\n",
      "Epoch 3/150\n",
      "892/892 - 243s - loss: 1.5696 - accuracy: 0.5350 - val_loss: 0.9671 - val_accuracy: 0.6102\n",
      "Epoch 4/150\n",
      "892/892 - 244s - loss: 1.4695 - accuracy: 0.5686 - val_loss: 1.1706 - val_accuracy: 0.5657\n",
      "Epoch 5/150\n",
      "892/892 - 244s - loss: 1.3979 - accuracy: 0.5834 - val_loss: 0.5762 - val_accuracy: 0.7969\n",
      "Epoch 6/150\n",
      "892/892 - 244s - loss: 1.3200 - accuracy: 0.6114 - val_loss: 0.7005 - val_accuracy: 0.7280\n",
      "Epoch 7/150\n",
      "892/892 - 243s - loss: 1.2230 - accuracy: 0.6426 - val_loss: 0.8861 - val_accuracy: 0.6936\n",
      "Epoch 8/150\n",
      "892/892 - 244s - loss: 1.1372 - accuracy: 0.6613 - val_loss: 0.5507 - val_accuracy: 0.7851\n",
      "Epoch 9/150\n",
      "892/892 - 243s - loss: 1.0950 - accuracy: 0.6749 - val_loss: 0.7083 - val_accuracy: 0.7162\n",
      "Epoch 10/150\n",
      "892/892 - 243s - loss: 1.0665 - accuracy: 0.6892 - val_loss: 0.5860 - val_accuracy: 0.7670\n",
      "Epoch 11/150\n",
      "892/892 - 243s - loss: 0.9765 - accuracy: 0.7123 - val_loss: 0.6774 - val_accuracy: 0.7053\n",
      "Epoch 12/150\n",
      "892/892 - 243s - loss: 0.9405 - accuracy: 0.7208 - val_loss: 0.7509 - val_accuracy: 0.7108\n",
      "Epoch 13/150\n",
      "892/892 - 243s - loss: 0.9062 - accuracy: 0.7387 - val_loss: 0.6323 - val_accuracy: 0.7761\n",
      "Epoch 14/150\n",
      "892/892 - 243s - loss: 0.8658 - accuracy: 0.7474 - val_loss: 0.4241 - val_accuracy: 0.8350\n",
      "Epoch 15/150\n",
      "892/892 - 243s - loss: 0.8805 - accuracy: 0.7462 - val_loss: 0.4187 - val_accuracy: 0.8441\n",
      "Epoch 16/150\n",
      "892/892 - 242s - loss: 0.7771 - accuracy: 0.7793 - val_loss: 0.8050 - val_accuracy: 0.7235\n",
      "Epoch 17/150\n",
      "892/892 - 242s - loss: 0.7515 - accuracy: 0.7892 - val_loss: 0.3814 - val_accuracy: 0.8667\n",
      "Epoch 18/150\n",
      "892/892 - 242s - loss: 0.6852 - accuracy: 0.8048 - val_loss: 0.4480 - val_accuracy: 0.8731\n",
      "Epoch 19/150\n",
      "892/892 - 243s - loss: 0.7267 - accuracy: 0.7994 - val_loss: 0.4032 - val_accuracy: 0.8314\n",
      "Epoch 20/150\n",
      "892/892 - 243s - loss: 0.7005 - accuracy: 0.7984 - val_loss: 0.3530 - val_accuracy: 0.8568\n",
      "Epoch 21/150\n",
      "892/892 - 243s - loss: 0.6386 - accuracy: 0.8177 - val_loss: 0.4858 - val_accuracy: 0.8214\n",
      "Epoch 22/150\n",
      "892/892 - 243s - loss: 0.6400 - accuracy: 0.8194 - val_loss: 0.3751 - val_accuracy: 0.8758\n",
      "Epoch 23/150\n",
      "892/892 - 243s - loss: 0.5906 - accuracy: 0.8311 - val_loss: 0.3748 - val_accuracy: 0.8731\n",
      "Epoch 24/150\n",
      "892/892 - 243s - loss: 0.6187 - accuracy: 0.8271 - val_loss: 0.4794 - val_accuracy: 0.8169\n",
      "Epoch 25/150\n",
      "892/892 - 243s - loss: 0.5508 - accuracy: 0.8484 - val_loss: 0.4750 - val_accuracy: 0.8359\n",
      "Epoch 26/150\n",
      "892/892 - 243s - loss: 0.5496 - accuracy: 0.8502 - val_loss: 0.3588 - val_accuracy: 0.8767\n",
      "Epoch 27/150\n",
      "892/892 - 243s - loss: 0.5240 - accuracy: 0.8543 - val_loss: 0.4791 - val_accuracy: 0.8468\n",
      "Epoch 28/150\n",
      "892/892 - 243s - loss: 0.4866 - accuracy: 0.8610 - val_loss: 0.3333 - val_accuracy: 0.8976\n",
      "Epoch 29/150\n",
      "892/892 - 243s - loss: 0.4561 - accuracy: 0.8731 - val_loss: 0.4062 - val_accuracy: 0.8432\n",
      "Epoch 30/150\n",
      "892/892 - 243s - loss: 0.4149 - accuracy: 0.8826 - val_loss: 0.3459 - val_accuracy: 0.8966\n",
      "Epoch 31/150\n",
      "892/892 - 243s - loss: 0.4418 - accuracy: 0.8775 - val_loss: 0.3629 - val_accuracy: 0.8658\n",
      "Epoch 32/150\n",
      "892/892 - 243s - loss: 0.4602 - accuracy: 0.8748 - val_loss: 0.3881 - val_accuracy: 0.8740\n",
      "Epoch 33/150\n",
      "892/892 - 243s - loss: 0.4088 - accuracy: 0.8898 - val_loss: 0.3755 - val_accuracy: 0.8694\n",
      "Epoch 34/150\n",
      "892/892 - 243s - loss: 0.3794 - accuracy: 0.8953 - val_loss: 0.3185 - val_accuracy: 0.8948\n",
      "Epoch 35/150\n",
      "892/892 - 243s - loss: 0.4143 - accuracy: 0.8870 - val_loss: 0.4658 - val_accuracy: 0.8377\n",
      "Epoch 36/150\n",
      "892/892 - 243s - loss: 0.4101 - accuracy: 0.8890 - val_loss: 0.4342 - val_accuracy: 0.8477\n",
      "Epoch 37/150\n",
      "892/892 - 243s - loss: 0.3570 - accuracy: 0.9001 - val_loss: 0.3315 - val_accuracy: 0.8876\n",
      "Epoch 38/150\n",
      "892/892 - 243s - loss: 0.3321 - accuracy: 0.9068 - val_loss: 0.3217 - val_accuracy: 0.8930\n",
      "Epoch 39/150\n",
      "892/892 - 243s - loss: 0.3230 - accuracy: 0.9100 - val_loss: 0.3737 - val_accuracy: 0.8876\n",
      "Epoch 40/150\n",
      "892/892 - 243s - loss: 0.3129 - accuracy: 0.9138 - val_loss: 0.3955 - val_accuracy: 0.8794\n",
      "Epoch 41/150\n",
      "892/892 - 244s - loss: 0.3120 - accuracy: 0.9139 - val_loss: 0.3122 - val_accuracy: 0.9039\n",
      "Epoch 42/150\n",
      "892/892 - 245s - loss: 0.3145 - accuracy: 0.9169 - val_loss: 0.3607 - val_accuracy: 0.8994\n",
      "Epoch 43/150\n",
      "892/892 - 243s - loss: 0.3006 - accuracy: 0.9188 - val_loss: 0.4091 - val_accuracy: 0.8767\n",
      "Epoch 44/150\n",
      "892/892 - 243s - loss: 0.3969 - accuracy: 0.9006 - val_loss: 0.3507 - val_accuracy: 0.8830\n",
      "Epoch 45/150\n",
      "892/892 - 243s - loss: 0.3110 - accuracy: 0.9157 - val_loss: 0.3388 - val_accuracy: 0.9003\n",
      "Epoch 46/150\n",
      "892/892 - 243s - loss: 0.3195 - accuracy: 0.9166 - val_loss: 0.4053 - val_accuracy: 0.8930\n",
      "Epoch 47/150\n",
      "892/892 - 244s - loss: 0.2884 - accuracy: 0.9182 - val_loss: 0.4114 - val_accuracy: 0.8785\n",
      "Epoch 48/150\n",
      "892/892 - 243s - loss: 0.2440 - accuracy: 0.9325 - val_loss: 0.3069 - val_accuracy: 0.9084\n",
      "Epoch 49/150\n",
      "892/892 - 243s - loss: 0.2635 - accuracy: 0.9283 - val_loss: 0.2938 - val_accuracy: 0.9093\n",
      "Epoch 50/150\n",
      "892/892 - 244s - loss: 0.2462 - accuracy: 0.9300 - val_loss: 0.3336 - val_accuracy: 0.9057\n",
      "Epoch 51/150\n",
      "892/892 - 243s - loss: 0.2876 - accuracy: 0.9241 - val_loss: 0.3823 - val_accuracy: 0.9003\n",
      "Epoch 52/150\n",
      "892/892 - 243s - loss: 0.2556 - accuracy: 0.9306 - val_loss: 0.3705 - val_accuracy: 0.9048\n",
      "Epoch 53/150\n",
      "892/892 - 244s - loss: 0.2506 - accuracy: 0.9320 - val_loss: 0.3762 - val_accuracy: 0.9012\n",
      "Epoch 54/150\n",
      "892/892 - 243s - loss: 0.2572 - accuracy: 0.9333 - val_loss: 0.3991 - val_accuracy: 0.8858\n",
      "Epoch 55/150\n",
      "892/892 - 244s - loss: 0.2295 - accuracy: 0.9396 - val_loss: 0.3280 - val_accuracy: 0.8921\n",
      "Epoch 56/150\n",
      "892/892 - 244s - loss: 0.2063 - accuracy: 0.9453 - val_loss: 0.3986 - val_accuracy: 0.8957\n",
      "Epoch 57/150\n",
      "892/892 - 243s - loss: 0.2404 - accuracy: 0.9357 - val_loss: 0.3345 - val_accuracy: 0.8957\n",
      "Epoch 58/150\n",
      "892/892 - 243s - loss: 0.2423 - accuracy: 0.9344 - val_loss: 0.2699 - val_accuracy: 0.9102\n",
      "Epoch 59/150\n",
      "892/892 - 242s - loss: 0.2142 - accuracy: 0.9400 - val_loss: 0.3521 - val_accuracy: 0.8948\n",
      "Epoch 60/150\n",
      "892/892 - 243s - loss: 0.2073 - accuracy: 0.9477 - val_loss: 0.3637 - val_accuracy: 0.8985\n",
      "Epoch 61/150\n",
      "892/892 - 243s - loss: 0.1733 - accuracy: 0.9537 - val_loss: 0.4725 - val_accuracy: 0.8867\n",
      "Epoch 62/150\n",
      "892/892 - 243s - loss: 0.1954 - accuracy: 0.9473 - val_loss: 0.3826 - val_accuracy: 0.8803\n",
      "Epoch 63/150\n",
      "892/892 - 243s - loss: 0.2272 - accuracy: 0.9420 - val_loss: 0.3352 - val_accuracy: 0.9084\n",
      "Epoch 64/150\n",
      "892/892 - 243s - loss: 0.1824 - accuracy: 0.9557 - val_loss: 0.3827 - val_accuracy: 0.9003\n",
      "Epoch 65/150\n",
      "892/892 - 243s - loss: 0.1995 - accuracy: 0.9505 - val_loss: 0.3446 - val_accuracy: 0.9012\n",
      "Epoch 66/150\n",
      "892/892 - 242s - loss: 0.1703 - accuracy: 0.9536 - val_loss: 0.3340 - val_accuracy: 0.9048\n",
      "Epoch 67/150\n",
      "892/892 - 244s - loss: 0.1642 - accuracy: 0.9576 - val_loss: 0.3097 - val_accuracy: 0.9139\n",
      "Epoch 68/150\n",
      "892/892 - 243s - loss: 0.1625 - accuracy: 0.9585 - val_loss: 0.3936 - val_accuracy: 0.8948\n",
      "Epoch 69/150\n",
      "892/892 - 242s - loss: 0.1497 - accuracy: 0.9584 - val_loss: 0.3954 - val_accuracy: 0.9021\n",
      "Epoch 70/150\n",
      "892/892 - 241s - loss: 0.1755 - accuracy: 0.9547 - val_loss: 0.3590 - val_accuracy: 0.8966\n",
      "Epoch 71/150\n",
      "892/892 - 241s - loss: 0.1450 - accuracy: 0.9596 - val_loss: 0.3997 - val_accuracy: 0.9066\n",
      "Epoch 72/150\n",
      "892/892 - 242s - loss: 0.1386 - accuracy: 0.9642 - val_loss: 0.3571 - val_accuracy: 0.9030\n",
      "Epoch 73/150\n",
      "892/892 - 242s - loss: 0.1355 - accuracy: 0.9661 - val_loss: 0.3974 - val_accuracy: 0.9157\n",
      "Epoch 74/150\n",
      "892/892 - 241s - loss: 0.0976 - accuracy: 0.9734 - val_loss: 0.4514 - val_accuracy: 0.9057\n",
      "Epoch 75/150\n",
      "892/892 - 242s - loss: 0.1224 - accuracy: 0.9687 - val_loss: 0.5007 - val_accuracy: 0.8849\n",
      "Epoch 76/150\n",
      "892/892 - 241s - loss: 0.1247 - accuracy: 0.9665 - val_loss: 0.3512 - val_accuracy: 0.9075\n",
      "Epoch 77/150\n",
      "892/892 - 242s - loss: 0.1440 - accuracy: 0.9635 - val_loss: 0.4120 - val_accuracy: 0.8903\n",
      "Epoch 78/150\n",
      "892/892 - 241s - loss: 0.1361 - accuracy: 0.9646 - val_loss: 0.3707 - val_accuracy: 0.9148\n",
      "Epoch 79/150\n",
      "892/892 - 242s - loss: 0.1290 - accuracy: 0.9663 - val_loss: 0.3846 - val_accuracy: 0.9112\n",
      "Epoch 80/150\n",
      "892/892 - 241s - loss: 0.1195 - accuracy: 0.9696 - val_loss: 0.3758 - val_accuracy: 0.9030\n",
      "Epoch 81/150\n",
      "892/892 - 244s - loss: 0.1076 - accuracy: 0.9709 - val_loss: 0.3842 - val_accuracy: 0.9102\n",
      "Epoch 82/150\n",
      "892/892 - 244s - loss: 0.1464 - accuracy: 0.9628 - val_loss: 0.3517 - val_accuracy: 0.9048\n",
      "Epoch 83/150\n",
      "892/892 - 244s - loss: 0.1261 - accuracy: 0.9638 - val_loss: 0.5461 - val_accuracy: 0.8885\n",
      "Epoch 84/150\n",
      "892/892 - 244s - loss: 0.1105 - accuracy: 0.9714 - val_loss: 0.3826 - val_accuracy: 0.9093\n",
      "Epoch 85/150\n",
      "892/892 - 245s - loss: 0.0919 - accuracy: 0.9739 - val_loss: 0.4029 - val_accuracy: 0.9148\n",
      "Epoch 86/150\n",
      "892/892 - 244s - loss: 0.1200 - accuracy: 0.9689 - val_loss: 0.3625 - val_accuracy: 0.9075\n",
      "Epoch 87/150\n",
      "892/892 - 242s - loss: 0.0934 - accuracy: 0.9767 - val_loss: 0.3694 - val_accuracy: 0.8966\n",
      "Epoch 88/150\n",
      "892/892 - 242s - loss: 0.1046 - accuracy: 0.9724 - val_loss: 0.4312 - val_accuracy: 0.8994\n"
     ]
    }
   ],
   "source": [
    "Earlystop = EarlyStopping(monitor='val_loss', mode='min',patience=30, min_delta=0.001)\n",
    "history = model.fit(train_batches,\n",
    "                    steps_per_epoch=(len(train_df)/10),\n",
    "                    epochs=150,\n",
    "                    verbose=2,\n",
    "                    validation_data=test_batches,validation_steps=len(test_df)/batch_size,callbacks=[checkpoint,Earlystop],class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm_AewFBXTj8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "model.load_weights(\"saved_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_batches, steps=len(test_df)/batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYxCDDjusR-S",
    "outputId": "bfc2b870-cdfa-4dce-cd6d-50bbe0591638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.75      0.50      0.60        30\n",
      "         bcc       0.88      0.86      0.87        35\n",
      "         bkl       0.79      0.65      0.71        88\n",
      "          df       1.00      0.25      0.40         8\n",
      "         mel       0.49      0.59      0.53        46\n",
      "          nv       0.96      0.98      0.97       883\n",
      "        vasc       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.92      1103\n",
      "   macro avg       0.83      0.68      0.72      1103\n",
      "weighted avg       0.92      0.92      0.91      1103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#geting predictions on test dataset\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "#getting the true labels per image \n",
    "y_true = test_batches.classes\n",
    "#getting the predicted labels per image \n",
    "y_prob=predictions\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test = to_categorical(y_true)\n",
    "\n",
    "# Creating classification report \n",
    "report = classification_report(y_true, y_pred, target_names=targetnames)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yy59Zs1jqylz",
    "outputId": "69536578-5dae-4460-9c57-4dd2b3a01adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9154027853026104\n",
      "Recall: 0.915684496826836\n",
      "Accuracy: 0.915684496826836\n",
      "weighted Roc score: 0.9797060373477102\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"weighted Roc score: \" + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFRWOB82sDKi",
    "outputId": "b5e08341-0cf1-41bd-e54a-dbf031d0a977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8277005983617955\n",
      "Recall: 0.6781119327694387\n",
      "Accuracy: 0.915684496826836\n",
      "Macro Roc score: 0.97934197360047\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='macro')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='macro')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"Macro Roc score: \" + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDNAPv9OsRVg",
    "outputId": "85e122fb-9638-4c83-b637-2c04ee598d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.915684496826836\n",
      "Recall: 0.915684496826836\n",
      "Accuracy: 0.915684496826836\n",
      "Micro Roc score: 0.9928636343585601\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='micro')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='micro')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "tpr={}\n",
    "fpr={}\n",
    "roc_auc={}\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_prob.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "print(\"Micro Roc score: \" + str(roc_auc[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U03sRDM2sudx",
    "outputId": "fdb1f32e-368e-4f64-8c7b-12ad2fd9dbb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC score of akiec is: 0.9580615097856477\n",
      "The ROC AUC score of bcc is: 0.9920278223649011\n",
      "The ROC AUC score of bkl is: 0.9724921630094044\n",
      "The ROC AUC score of df is: 0.9984018264840183\n",
      "The ROC AUC score of mel is: 0.9530253794578587\n",
      "The ROC AUC score of nv is: 0.9815968289920725\n",
      "The ROC AUC score of vasc is: 0.9997882851093861\n"
     ]
    }
   ],
   "source": [
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(7):\n",
    "    r = roc_auc_score(y_test[:, i], y_prob[:, i])\n",
    "    print(\"The ROC AUC score of \"+targetnames[i]+\" is: \"+str(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5nG-b11wkep"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = dict()\n",
    "for i in range(7):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_prob[:, i], drop_intermediate=False)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "9wz2--WDwHQ4",
    "outputId": "5206743a-caa3-49c6-b8eb-e1968c463828"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(fpr[0], tpr[0],'v-',label='akiec: ROC curve of (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot(fpr[1], tpr[1],'c',label='bcc: ROC curve of (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot(fpr[2], tpr[2],'b',label='bkl: ROC curve of (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot(fpr[3], tpr[3],'g',label='df: ROC curve of (area = %0.2f)' % roc_auc[3])\n",
    "plt.plot(fpr[4], tpr[4],'y',label='mel: ROC curve of (area = %0.2f)' % roc_auc[4])\n",
    "plt.plot(fpr[5], tpr[5],'o-',label='nv: ROC curve of (area = %0.2f)' % roc_auc[5])\n",
    "plt.plot(fpr[6], tpr[6],'r',label='vasc: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic of %s'%targetnames[i])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "IRV2+SA_20split.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
